{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2\n",
    "\n",
    "Please upload to Moodle a .zip archive containing your Jupyter Notebook with solutions and all data required to reproduce your solutions. \n",
    "\n",
    "Please also prepare a requirements.txt file which lists all the packages that you have used for your homework, one package per line (e.g., pandas). This will allow us to install all required packages in one go, by using \"pip install -r requirements.txt\".\n",
    "\n",
    "Please name your .zip archive using your full name and student id as follows - *Firstnme_Lastname_12345678_COMP47350_Homework2.zip*. \n",
    "\n",
    "For your Notebook, please split the code and explanations into many little cells so it is easy to see and read the results of each step of your solution. Please remember to name your variables and methods with self-explanatory names. Please remember to write comments and where needed, justifications, for the decisions you make and code you write. Feel free to revisit *tips_to_keep_your_ipython_notebook_readable_and_easy_to_debug.html* provided on Moodle.\n",
    "\n",
    "Your code and analysis is like a story that awaits to be read, make it a nice story please!\n",
    "\n",
    "The accepted file formats for the homework are:\n",
    "    - .ipynb\n",
    "    - .zip\n",
    "    - .pdf\n",
    "    - .csv\n",
    "    - .txt\n",
    "    - .html\n",
    "Please keep the whole code in a single notebook. Usage of external tools/files is discouraged for portability reasons. Files in any other format but mentioned above can be used but will be ignored and not considered for the submission (including .doc, .rar, .7z, .pages, .xlsx, .tex etc.). \n",
    "Any image format is allowed to be used as far as the images appear embedded in your report (.ipynb or .pdf or .html).\n",
    "\n",
    "**Deadline: Sunday, April 16, 2017, midnight.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "This homework focuses on building and evaluating prediction models for a particular problem and dataset.\n",
    "The problem and data come from the Amazon online shopping platform. Several sellers can sell the same product on Amazon. Based on the data provided by the seller to Amazon (seller reputation, product price, shipping details, etc) Amazon ranks seller offers from best to worst for a given product. This ranking is mostly influenced by the product price offer of the seller, but it can also be influenced by other features. We first need to understand which features are most indicative of a seller being ranked first by Amazon for a product. When the seller is ranked first for a product we say that the seller is the 'winner' among all the offers, because their offer is shown first when a user searches for a product on Amazon, which increases their chances of selling the product. Our goal is to work with the data to build and evaluate prediction models that capture the relationship between descriptive features and the target feature 'IsWinner'.\n",
    "\n",
    "We use the same dataset from Homework1 (you can use your cleaned/prepared CSV or the raw dataset), a CSV file describing offers by given sellers for given products and a column which records whether an offer was a winner or not.\n",
    "\n",
    "(1). [25] Data Understanding: Exploring relationships between feature pairs:\n",
    "    - (1.1) [5] Print the correlations between the continuous features.\n",
    "    - (1.2) [5] Plot the scatter plots of each pair of continuous descriptive feature and target feature.\n",
    "    - (1.3) [5] Discuss what you observe from the scatter plots and correlations, e.g., which continuous features seem to be better at predicting the target feature. Choose a subset of continuous features you find promising. Justify your choices.\n",
    "    - (1.4) [5] For each categorical feature, plot the pairwise interaction with the target feature (barplots or stacked barplots).\n",
    "    - (1.5) [5] Discuss what knowledge you gain from plotting the interaction of descriptive categorical features and the target feature, e.g., which categorical features seem to be better at predicting the target feature. Choose a subset of categorical features you find promising. Justify your choices.\n",
    "    \n",
    "(2). [15] Predictive Modeling: Linear Regression  \n",
    "    - (2.1) [5] Train a linear regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.   \n",
    "    - (2.2) [2.5] Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).    \n",
    "    - (2.3) [2.5] Retrain the model using only the subset of features found to be statistically significant. Evaluate the quality of the model on the training set.\n",
    "    - (2.4) [5] Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Threshold the predicted target feature value at 0.5 to get the predicted class for each example. \n",
    "\n",
    "(3). [15] Predictive Modeling: Logistic Regression  \n",
    "    - (3.1) [5] Train a logistic regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.   \n",
    "    - (3.2) [5] Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).    \n",
    "    - (3.3) [2.5] Retrain the model using only the subset of features found to be statistically significant. Evaluate the quality of the model on the training set.\n",
    "    - (3.4) [2.5] Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example.\n",
    "    \n",
    "(4). [20] Predictive Modeling: Random Forest \n",
    "    - (4.1) [5] Train a random forest model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.   \n",
    "    - (4.2) [5] Print the features ranked by random forest importance. Discuss your findings and choose a subset of features you find promising.\n",
    "    - (4.3) [5] Retrain the model using only the subset of features found to be promising. Evaluate the quality of the model on the training set.\n",
    "    - (4.4) [5] Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example.\n",
    "    \n",
    "(5). [25] Evaluating Predictive Models\n",
    "    - (5.1) [10] Split the dataset into 70% training and remaining 30% test. Train all models from the previous exercises using the new training set and evaluate their quality on the new test set. Print classification evaluation metrics for all models on the test set (e.g., Accuracy, Confusion matrix, Precision, Recall, F1). Discuss how does evaluation on the test set compare to evaluation using the full data for training and also for testing.\n",
    "    - (5.2) [15] Summarize and try to improve your results so far:\n",
    "        - (5.2.1) [5] Which model performs best and is it more accurate than a simple (but useless) model that always predicts IsWinner=0? Justify your answers.\n",
    "        - (5.2.2) [10] Discuss your understanding of the problem and predictive modeling results so far. Can you find any tricks to improve the best model so far (e.g., using feature significance, feature re-scaling, creating new features, combining models, or other knowledge)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon-offers-10k-samples-new2.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying Up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropping columns unamed(created as a result of reading in the csv)\n",
    "# Dropping ProductId, TimeOfOfferChange, ConditionNotes, IsFulfilledByAmazon\n",
    "# and SellerId. \n",
    "# These are still present in the csv - so I haven't removed them completely\n",
    "# Just from the data frame for the purposes of creating predictive models\n",
    "df.drop(df.columns[[0, 2, 3, 4, 6, 10]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107.35</td>\n",
       "      <td>95</td>\n",
       "      <td>4078</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.46</td>\n",
       "      <td>98</td>\n",
       "      <td>478</td>\n",
       "      <td>6.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99.24</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>11.67</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.48</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>8.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.70</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>6.98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "0         1                   1        107.35                    95   \n",
       "1         0                   1        100.46                    98   \n",
       "2         0                   1         99.24                    95   \n",
       "3         0                   0        109.48                    94   \n",
       "4         0                   0        116.70                    67   \n",
       "\n",
       "   SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "0                 4078           0.00                     48   \n",
       "1                  478           6.99                     24   \n",
       "2                 4384          11.67                     24   \n",
       "3                  105           8.99                     24   \n",
       "4                    9           6.98                     24   \n",
       "\n",
       "   ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "0                     72               CA             ON  \n",
       "1                     48               CA             ON  \n",
       "2                     48               CA             ON  \n",
       "3                     48               CA             ON  \n",
       "4                     48               CA             AB  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsWinner                 0\n",
       "IsFeaturedMerchant       0\n",
       "ListingPrice             0\n",
       "SellerFeedbackRating     0\n",
       "SellerFeedbackCount      0\n",
       "ShippingPrice            0\n",
       "ShippingTime_minHours    0\n",
       "ShippingTime_maxHours    0\n",
       "ShipsFromCountry         0\n",
       "ShipsFromState           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check for null values (shouldn't be any - removed them in the last assignment)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2999.00</td>\n",
       "      <td>95</td>\n",
       "      <td>4385</td>\n",
       "      <td>12.52</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2999.00</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>12.12</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2617.92</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2237.85</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>269.65</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2093.77</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "2865         0                   1       2999.00                    95   \n",
       "73           0                   1       2999.00                    95   \n",
       "2684         0                   0       2617.92                    96   \n",
       "2683         0                   1       2237.85                    93   \n",
       "2290         0                   0       2093.77                    98   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "2865                 4385          12.52                     24   \n",
       "73                   4384          12.12                     24   \n",
       "2684                 1790           9.98                     96   \n",
       "2683                 2521         269.65                     24   \n",
       "2290                 1446           0.00                     24   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "2865                     48               CA             ON  \n",
       "73                       48               CA             ON  \n",
       "2684                    120               US             NY  \n",
       "2683                     48               US             VA  \n",
       "2290                     48               US             CA  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers in Listing Price\n",
    "# Results look normal - there is a gradual decrease in price\n",
    "df.sort_values(by='ListingPrice', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>30.22</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>95</td>\n",
       "      <td>2283</td>\n",
       "      <td>8.07</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>95</td>\n",
       "      <td>2283</td>\n",
       "      <td>8.07</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>7.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>7.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "393          0                   1          3.24                   100   \n",
       "75           0                   1          3.94                    95   \n",
       "4727         0                   1          3.94                    95   \n",
       "3591         0                   0          4.57                    98   \n",
       "1469         0                   0          4.86                    98   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "393                     2          30.22                     24   \n",
       "75                   2283           8.07                    144   \n",
       "4727                 2283           8.07                    144   \n",
       "3591                 3293           7.99                     24   \n",
       "1469                 3293           7.99                     24   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "393                      48               US             NH  \n",
       "75                      240               CA             BC  \n",
       "4727                    240               CA             BC  \n",
       "3591                     48               US             NY  \n",
       "1469                     48               US             NY  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers at the other end for Listing Price\n",
    "# This also looks fine - There are no zero values. \n",
    "df.sort_values(by='ListingPrice', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.81</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>13.08</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.98</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>13.86</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>444.53</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>20.26</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99.61</td>\n",
       "      <td>100</td>\n",
       "      <td>4601</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.75</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>13.09</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "4201         0                   1        105.81                   100   \n",
       "1567         0                   1         55.98                   100   \n",
       "4340         0                   1        444.53                   100   \n",
       "2830         0                   1         99.61                   100   \n",
       "3439         0                   0         92.75                   100   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "4201                  384          13.08                     24   \n",
       "1567                  384          13.86                     24   \n",
       "4340                  384          20.26                     24   \n",
       "2830                 4601           0.00                     24   \n",
       "3439                  384          13.09                     24   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "4201                     48               CA             ON  \n",
       "1567                     48               CA             ON  \n",
       "4340                     48               CA             ON  \n",
       "2830                     48               CA             ON  \n",
       "3439                     48               CA             ON  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers in Seller Feedback Rating\n",
    "# Looks fine also - 100 is the maximum that should be possible\n",
    "df.sort_values(by='SellerFeedbackRating', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "5130         0                   0        144.70                     0   \n",
       "1481         0                   0        240.10                     0   \n",
       "2990         0                   0        216.32                     0   \n",
       "2987         0                   0        188.25                     0   \n",
       "4511         0                   0         95.81                     0   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "5130                    0          58.00                     48   \n",
       "1481                    0           6.98                     96   \n",
       "2990                    0           5.54                     48   \n",
       "2987                    0           5.54                     96   \n",
       "4511                    0           5.54                    504   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "5130                     72               US             CA  \n",
       "1481                    120               US             FL  \n",
       "2990                     72               US             CA  \n",
       "2987                    120               US             PA  \n",
       "4511                    720               CA             ON  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now here we can see a lot of zeros - are these legitimate zero ratings or lack or rating? \n",
    "# Either way it does provide us with useful information if it correlates with the target feature\n",
    "df.sort_values(by='SellerFeedbackRating', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>929.02</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>335.35</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>929.02</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>335.35</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>929.02</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>335.35</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2237.85</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>269.65</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575.25</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>252.25</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "531          0                   1        929.02                    93   \n",
       "2137         0                   1        929.02                    93   \n",
       "4251         0                   1        929.02                    93   \n",
       "2683         0                   1       2237.85                    93   \n",
       "764          0                   1        575.25                    93   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "531                  2521         335.35                     24   \n",
       "2137                 2521         335.35                     24   \n",
       "4251                 2521         335.35                     24   \n",
       "2683                 2521         269.65                     24   \n",
       "764                  2521         252.25                     24   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "531                      48               US             VA  \n",
       "2137                     48               US             VA  \n",
       "4251                     48               US             VA  \n",
       "2683                     48               US             VA  \n",
       "764                      48               US             VA  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers in Shipping Price\n",
    "# Looks fine, decreases at a normal enough rate. No outstanding values at the top. \n",
    "df.sort_values(by='ShippingPrice', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107.35</td>\n",
       "      <td>95</td>\n",
       "      <td>4078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>471.32</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481.98</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>498.01</td>\n",
       "      <td>95</td>\n",
       "      <td>4078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>570.44</td>\n",
       "      <td>96</td>\n",
       "      <td>35270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "0            1                   1        107.35                    95   \n",
       "2741         0                   0        471.32                    98   \n",
       "2742         0                   0        481.98                    94   \n",
       "2743         0                   1        498.01                    95   \n",
       "2750         0                   1        570.44                    96   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "0                    4078            0.0                     48   \n",
       "2741                   63            0.0                     24   \n",
       "2742                  105            0.0                     24   \n",
       "2743                 4078            0.0                     48   \n",
       "2750                35270            0.0                     96   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "0                        72               CA             ON  \n",
       "2741                     48               CA             ON  \n",
       "2742                     48               CA             ON  \n",
       "2743                     72               CA             ON  \n",
       "2750                    120               CA             QC  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers in Shipping Price at the lower end\n",
    "# Again there are a lot of zeros, but this could be legitimate because it's not uncommon \n",
    "# to get free shipping on Amazon\n",
    "df.sort_values(by='ShippingPrice', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>499.00</td>\n",
       "      <td>93</td>\n",
       "      <td>3182</td>\n",
       "      <td>30.50</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78.09</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>13.27</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.59</td>\n",
       "      <td>98</td>\n",
       "      <td>478</td>\n",
       "      <td>6.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86.72</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>9.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.13</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>21.45</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "2925         0                   0        499.00                    93   \n",
       "3296         0                   1         78.09                   100   \n",
       "3297         0                   1         87.59                    98   \n",
       "3298         0                   1         86.72                    96   \n",
       "3301         0                   1         80.13                    93   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "2925                 3182          30.50                     24   \n",
       "3296                  384          13.27                     24   \n",
       "3297                  478           6.99                     24   \n",
       "3298                 7090           9.95                     24   \n",
       "3301                 2521          21.45                     24   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "2925                     48               CA             ON  \n",
       "3296                     48               CA             ON  \n",
       "3297                     48               CA             ON  \n",
       "3298                     48               CA             ON  \n",
       "3301                     48               US             VA  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers for Shipping Times - more likely to be at the lower end\n",
    "# Looks fine - minimum is 24hrs which seems reasonable for domestic shipping\n",
    "df.sort_values(by='ShippingTime_minHours', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>504</td>\n",
       "      <td>720</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  IsFeaturedMerchant  ListingPrice  SellerFeedbackRating  \\\n",
       "5352         0                   0        376.68                     0   \n",
       "1883         0                   0        376.68                     0   \n",
       "4757         0                   0        376.68                     0   \n",
       "5630         0                   0        376.68                     0   \n",
       "2982         0                   0        105.97                     0   \n",
       "\n",
       "      SellerFeedbackCount  ShippingPrice  ShippingTime_minHours  \\\n",
       "5352                    0           5.54                    504   \n",
       "1883                    0           5.54                    504   \n",
       "4757                    0           5.54                    504   \n",
       "5630                    0           5.54                    504   \n",
       "2982                    0           5.54                    504   \n",
       "\n",
       "      ShippingTime_maxHours ShipsFromCountry ShipsFromState  \n",
       "5352                    720               CA             ON  \n",
       "1883                    720               CA             ON  \n",
       "4757                    720               CA             ON  \n",
       "5630                    720               CA             ON  \n",
       "2982                    720               CA             ON  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers for Shipping Times - more likely to be at the higher end\n",
    "# 720 hours (30 days) does seem high but as there are a few instances of that time\n",
    "# And the ShipsFromCountry is Canada I'll make the decision that it passes the sanity check\n",
    "df.sort_values(by='ShippingTime_maxHours', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 1. Data Understanding: Exploring Relationships Between Feature Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Print the correlations between the continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       SellerFeedbackRating  SellerFeedbackCount  \\\n",
      "SellerFeedbackRating               1.000000             0.105576   \n",
      "SellerFeedbackCount                0.105576             1.000000   \n",
      "ListingPrice                      -0.037842            -0.001166   \n",
      "ShippingPrice                     -0.005308            -0.202074   \n",
      "ShippingTime_minHours             -0.163926             0.295287   \n",
      "ShippingTime_maxHours             -0.176798             0.212978   \n",
      "\n",
      "                       ListingPrice  ShippingPrice  ShippingTime_minHours  \\\n",
      "SellerFeedbackRating      -0.037842      -0.005308              -0.163926   \n",
      "SellerFeedbackCount       -0.001166      -0.202074               0.295287   \n",
      "ListingPrice               1.000000       0.215024               0.038674   \n",
      "ShippingPrice              0.215024       1.000000              -0.016701   \n",
      "ShippingTime_minHours      0.038674      -0.016701               1.000000   \n",
      "ShippingTime_maxHours      0.032914       0.036349               0.973911   \n",
      "\n",
      "                       ShippingTime_maxHours  \n",
      "SellerFeedbackRating               -0.176798  \n",
      "SellerFeedbackCount                 0.212978  \n",
      "ListingPrice                        0.032914  \n",
      "ShippingPrice                       0.036349  \n",
      "ShippingTime_minHours               0.973911  \n",
      "ShippingTime_maxHours               1.000000  \n"
     ]
    }
   ],
   "source": [
    "sns.set(style='white')\n",
    "continuous_features = df[['SellerFeedbackRating', 'SellerFeedbackCount', 'ListingPrice', 'ShippingPrice', 'ShippingTime_minHours', 'ShippingTime_maxHours']].columns\n",
    "corr = df[continuous_features].corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5]),\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAJUCAYAAAALuN5mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERBzevwCbcH51DWm8pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146f1f0710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A nicer representation of correlations\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom colormap - blue and red\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, annot=True, mask=mask, cmap=cmap, vmax=1, vmin=-1,\n",
    "            square=True, xticklabels=True, yticklabels=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Plot the scatter plots of each pair of continuous descriptive feature and target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146b367d30>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAE8CAYAAABJkJPnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDbLpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146f1c6ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "df.plot(kind='scatter', x='IsWinner', y='SellerFeedbackRating', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146ee92780>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAE8CAYAAACbwJm/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHSlJREFUeJzt3X+8VXWd7/HXARVQD1x/PAhnmBGu5jtnrhiRYAINhkZQ\nXrt1rTui42ipmKPZeNNSzLwPHNPxR2ozUPgLFScnUysmhTr+AE8jFFnqZJ8E8dEw6aSWgIOAwL5/\nfNeRzemcvdeBtc45+5z38/E4D/b67rX2+SzhvP2etb7r+22qVCqYmVlxBvR0AWZmfY2D1cysYA5W\nM7OCOVjNzArmYDUzK9gePV1AmSQNAo4CXgK29XA5ZtZ3DAQOAn4cEZvbv9mng5UUqst6uggz67Mm\nA0+0b+zrwfoSwMKFCxkxYkRP12JmfcTLL7/MzJkzIcuY9vp6sG4DGDFiBCNHjuzpWsys7+nwEqNv\nXpmZFczBamZWMAermVnBHKxmZgVzsJqZFczBamZWMAermVnB+vo41l1ywoXf+YO27113Yg9UYmZl\nKfPnvLRglTQQmA8IqACzgD2BRcDz2W5zI+JeSWcCZwNbgTkRsUjSEOBuYDiwATgtIl6RdDRwY7bv\nkoi4oqxzMDPbFWVeCjgBICImArOBK4FxwPURMSX7ulfSCOB8YCIwDbgqmzzlHOCZiJgM3Jl9BsA8\n4GRgEjBB0tgSz8HMrMtKC9aIeBA4K9s8GHidFKwflrRU0q2SmoHxQGtEbI6IdcAqYAwpOB/Ojn8I\nOE7SUGBQRKyOiAqwGDiurHMwM9sVpd68ioitkhYANwMLgRXA5yPi/cALwOXAUGBd1WEbgGHt2qvb\n1newr5lZr1H6zauIOE3SxcBy4JiI+I/srQdIgbsUaK46pJnUu11f1d5RW3V7oXyjyqzvK/PnvLQe\nq6RTJX0x29wIbAfulzQ+a5sKrCT1YidLGixpGHA48CzQCszI9p0OLIuI9cAWSYdIaiJdk/V8q2bW\nq5TZY70fuF3SUtJogAuAfwdulvQW8DJwVkSsl3QTKSAHAJdGxCZJc4EFkp4AtpBuWEEaXbCQNIP3\nkohYXuI5mJl1WVOlUunpGkojaRSwpqWlxfOxmllh1q5dy9SpUwFGR8SL7d/3k1dmZgVzsJqZFczB\namZWMAermVnBHKxmZgVzsJqZFczBamZWMAermVnBHKxmZgVzsJqZFczBamZWMAermVnBHKxmZgVz\nsJqZFczBamZWMAermVnBHKxmZgVzsJqZFczBamZWMAermVnBHKxmZgVzsJqZFczBamZWMAermVnB\nHKxmZgVzsJqZFczBamZWsD3K+mBJA4H5gIAKMAvYBNyRbT8LnBsR2yWdCZwNbAXmRMQiSUOAu4Hh\nwAbgtIh4RdLRwI3Zvksi4oqyzsHMbFeU2WM9ASAiJgKzgSuB64HZETEZaAJOlDQCOB+YCEwDrpI0\nCDgHeCbb987sMwDmAScDk4AJksaWeA5mZl1WWrBGxIPAWdnmwcDrwDjg8aztIeA4YDzQGhGbI2Id\nsAoYQwrOh6v3lTQUGBQRqyOiAizOPsPMrNco9RprRGyVtAC4GVgINGWBCOnX+2HAUGBd1WEdtVe3\nre9gXzOzXqP0m1cRcRpwGOl665Cqt5pJvdj12eta7fX2NTPrNUoLVkmnSvpitrkR2A78RNKUrG06\nsAxYAUyWNFjSMOBw0o2tVmBG9b4RsR7YIukQSU2ka7LLyjoHM7NdUdqoAOB+4HZJS4E9gQuA54D5\nkvbKXt8XEdsk3UQKyAHApRGxSdJcYIGkJ4AtpBtWkEYXLAQGkkYFLC/xHMzMuqypUqnU36tBSRoF\nrGlpaWHkyJE9XY6Z9RFr165l6tSpAKMj4sX27/sBATOzgjlYzcwK5mA1MyuYg9XMrGAOVjOzgjlY\nzcwK5mA1MyuYg9XMrGAOVjOzgjlYzcwK5mA1MyuYg9XMrGAOVjOzgjlYzcwK5mA1MyuYg9XMrGAO\nVjOzgjlYzcwK5mA1MyuYg9XMrGAOVjOzgjlYzcwK5mA1MyuYg9XMrGAOVjOzgjlYzcwK5mA1MyvY\nHmV8qKQ9gduAUcAgYA7w78Ai4Plst7kRca+kM4Gzga3AnIhYJGkIcDcwHNgAnBYRr0g6Grgx23dJ\nRFxRRv1mZrujrB7rKcBrETEZ+BDwNWAccH1ETMm+7pU0AjgfmAhMA66SNAg4B3gmO/5OYHb2ufOA\nk4FJwARJY0uq38xsl5XSYwW+BdyXvW4i9TDHAZJ0IqnXegEwHmiNiM3AZkmrgDGk4LwmO/4h4DJJ\nQ4FBEbGa9EGLgeOAp0o6BzOzXbLLPVZJe3X2XkS8EREbJDWTAnY2sAL4fES8H3gBuBwYCqyrOnQD\nMKxde3Xb+g72NTPrVXIFq6R/bbc9AFhZ55g/AR4F7oqIe4AHIqLtmAeAsaSgbK46rBl4vV17R23V\n7WZmvUrNSwGSHgGmZK+3V721FfhujePeASwB/iYiWrLmxZLOi4gVwFRSMK8ArpQ0mHST63DgWaAV\nmJG9Px1YFhHrJW2RdAipxzsN8M0rM+t1agZrRHwAQNKNEfHZLnzuJcB+pGujl2VtfwvcIOkt4GXg\nrCwsbwKWkXrPl0bEJklzgQWSngC2kG5YAcwCFgIDSaMClnehJjOzbtFUqVTq7pQNn/ogsD/pZhQA\nEXFneaXtPkmjgDUtLS2MHDmyp8sxsz5i7dq1TJ06FWB0RLzY/v28owIWAgcDzwFtSVwhDYUyM7Mq\neYN1TES8q9RKzMz6iLzDrZ6TdFCplZiZ9RF5e6x7AyHpWWBTW2PbzS0zM9shb7D+XalVmJn1IXmD\ntf7QATMzA/IHa/VA/D1Jz/MvA5YWXpGZWYPLFawRcWz1tqTRwA2lVGRm1uB2aRKWiFgDePiVmVkH\ncvVYJd3OjuusTex4pt/MzNrJe431sarXFdJ8qz8svBozsz4g16WAiFhAmo2qmTRfwG8iYkuZhZmZ\nNaq887GeCnwHGE2aM+B+SWeUWZiZWaPKeyngQmB8RLwGIOlK0uWB20qqy8ysYeUdFTCwLVQBIuJV\nYHuN/c3M+q28PdafS/oqcGu2/Sng5+WUZGbW2PL2WM8ENpN+9b8DeAv4TEk1mZk1tLw91s0RcTGA\npOER8dsSazIza2g1e6ySDpD0OHBSVfNcSUsl7V9uaWZmjanepYAbgYdJDwS0+d9AC/DVsooyM2tk\n9S4FHBERp1Q3REQFuCKb9NrMzNrZpUlYMtsKq8LMrA+pF6wvSprRvlHSh4BXyinJzKyx1bsUcBHw\niKTFwHLSzFZHATOA6SXXZmbWkGr2WCMigPcCa4GPkML0ReDdEfGz0qszM2tAdcexRsRLku6IiC9V\nt0s6LyJuLq80M7PGlPfm1fclHQog6QhJy4GPlleWmVnjyvvk1RnAdyX9APg48MWIuKuznSXtSXr8\ndRQwCJgD/IL0OGyFtPrAuRGxXdKZwNnAVmBORCySNAS4GxgObABOi4hXJB1NGlu7FVgSEVdgZtbL\n5J3o+kfAX5KewDqlVqhmTgFei4jJwIeArwHXA7OztibgREkjgPOBicA04CpJg4BzgGeyfe8EZmef\nOw84GZgETJA0NveZmpl1k5o9Vknb2XmtK4AWSU1AJSIGdnLot4D7qo7bCowDHs/aHgI+SBoL2xoR\nm4HNklaRltaeBFxTte9lkoYCgyJidVbbYuA44Kmc52pm1i1qBmtE/EGPVlJT9vRVrePeyPZtJgXs\nbODaquM2AMOAocC6qkM7aq9uW99u3/9eqw4zs56Qd2mWKZJas83DJL0g6Zg6x/wJ8ChwV0Tcw84T\nYzcDr5OCsrlOe719zcx6lbyjAq4n3WBqG9s6g3QTqUOS3gEsAS6OiLblW56SNCV7PR1YBqwAJksa\nLGkYO5bVbs2+x9v7RsR6YIukQ7JLEdOyzzAz61XyjgoYHBFvT7oSEb/M7vx35hJgP9K10cuyts8C\nN0naC3gOuC8itkm6iRSQA4BLI2KTpLnAAklPAFtIN6wAZgELgYGkUQHLc9ZvZtZtmiqVmpdLAZB0\nP/A80DYa4P8Ah0XEJ0qsbbdJGgWsaWlpYeTIkT1djpn1EWvXrmXq1KkAoyPixfbv570U8ClgX+Cf\nSMOf9iUt12JmZu3kuhQQEb8Hzm3bzq5xjmbnO/pmZkbOYJV0HnAlsE9V84vAISXUZGbW0PJeCvhb\n4EjgXlKYfgp4sqyizMwaWd5g/W1ErAGeJi3Xcgeg0qoyM2tgeYP1vyQdSwrWE7Jn/Pcrrywzs8aV\nN1jPA/4nacXWA4BfAp6L1cysA3lHBfwb8LlsIpSZEbGp3LLMzBpX3lEBRwALgIOBiqRfkuZIXV1m\ncWZmjSjvpYB5pMdND4iIA4HrSBNZm5lZO3mDdUhEPNS2EREPkKbxMzOzdupNdP2n2cufS/oCcCtp\n0uqZeGYpM7MO1bvG+njV6ylkUwdmKqRlVczMrEq9FQRGd1chZmZ9Rb1LATVvUEXEGcWWY2bW+Ord\nvHo8+2oG/gh4hLQywH45jjUz65fqXQpYACDpM8D7ImJ7tv3PeBIWM7MO5e11DgP2r9p+B2myazMz\nayfvmldXAk9nK7UOBCaQ5g8wM7N2cvVYI+IuYBzwTeBuYGxE3F9mYWZmjSpXsGYrq54OnAi0ALOy\nNjMzayfvNdZ/IF1TfQ/wFnAo6SksMzNrJ2+wjouIS4C3ImIjcBowtryyzMwaV95grWS/+ley7QOr\nXpuZWZW8wfpV4IfAQZK+CvwEuKG0qszMGljeFQTukrQSOJY03OqEiHi61MrMzBpUVx5LfTfpsdZb\ns9dmZtaBvEuzfAUYSRrLejVwuqQjI+LCOsdNAK6OiCmSxgKLgOezt+dGxL2SziRNR7gVmBMRiyQN\nIY2XHQ5sIC0D84qko4Ebs32XRMQVXT1hM7Oy5e2xTgNOBTZFxHrgeGB6rQMkXQTcAgzOmsYB10fE\nlOzr3mwZ7fOBidn3uErSIOAc4JmImAzcCczOPmMecDIwCZiQhbWZWa+SN1i3Z3+2jQQYVNXWmdXA\nx6q2xwEflrRU0q2SmoHxQGtEbI6IdcAqYAwpOB/OjnsIOC5bIXZQRKyOiAqwGDguZ/1mZt0mb7D+\nM3AvsL+kC4ClwD21DoiIb5MeJmizAvh8RLwfeAG4nLRu1rqqfTaQJnypbq9uW9/BvmZmvUreuQKu\nJt20+hbwp8DlEfF3XfxeD0TEyrbXpAcM1pPmem3TDLzerr2jtup2M7Nepd4KAudExFyAiFhM+vV7\nVy2WdF5ErACmAitJvdgrJQ0mXV44HHgWaAVmZO9PB5ZFxHpJWyQdQurxTgN888rMep16PdYz215I\nerzWjjmcA9wg6THSzao5EfEycBNpxddHgEsjYhMwF/hzSU8AZ7EjQGcBC0mB+1RELN/NmszMCldv\nuFVT1euhXf3wiHgRODp7/VNSoLbfZz4wv13bRuCkDvZ9su3zzMx6q3o91konr83MrBP1eqzNkiaT\nAnjf7PXbvdiIWFpmcWZmjahesK4F/l/2+j+qXkPqwX6gjKLMzBpZvVVajwWQ9JGIWNQ9JZmZNba8\nDwhcXWoVZmZ9SN5VWldLug1YDrzZ1hgRd5ZSlZlZA8sbrK+RblpVD3WqkCZIMTOzKnknuj4dQNJ+\nEfH7cksyM2tseedjPZI0Ccve2ZyoS4FPZIP+zcysSt6bVzcD/wt4LSJ+Q3o8dV5pVZmZNbC8wbp3\nRDzXthERPyBNmmJmZu3kDdbfZZcDKgCSZgK/K60qM7MGlndUwDnAAtKMU6+T1q06pbSqzMwaWN5R\nAauBSZL2AQZm616ZmVkH6k10/SgdzGolCYCI8FwBZmbt1Ouxfrk7ijAz60vqBavnYDUz66J6wVpr\nTSlPG2hm1oFc0waamVl+eR9pPRi4BRgFTAbuAc7I1rQyM7MqeR8Q+Drw98AbwH8C/4RntjIz61De\nYD0wIpYAREQlW1m1y6u2NoplP13LCRd+5+2vJ36+tqdLMrMGkjdY35Q0kh2PtE4CNpdWVQ+7ZuHK\nnbavvnNlJ3uamf2hvI+0fg5YBBwi6WfA/sBJpVVlZtbA6vZYJX2ENOHKUcA12eu7AHfjzMw6UDNY\nJf1f4HJgMHA48AXSiIAhwLWlV9dDLv6rcTW3zcxqqXcp4FTgfRGxUdJXgO9GxC2SmoBflF9ez5h0\n5EgmXTeyp8swswZV95HWiNiYvT4W+EdIIwPaJmKpRdIE4OqImCLpUOAO0g2wZ4FzI2K7pDOBs4Gt\nwJyIWCRpCHA3MBzYAJwWEa9ky8LcmO27JCJqPRm2y0648Dt/0Pa9604s41uZWQ8p8+e83jXWrZL+\nWzYiYCywBN5+YGBrrQMlXUR6qGBw1nQ9MDsiJpNWfD1R0gjgfGAiMA24StIg0vyvz2T73gnMzj5j\nHnAyMAmYIGlsV07WzKw71AvWrwA/A54EbomIlyR9Amgh3ciqZTXwsartccDj2euHgOOA8UBrRGyO\niHXAKmAMKTgfrt5X0lBgUESsjogKsDj7DDOzXqVmsEbEfcAxwIyI+EzW/Abw6Yi4q86x3wbeqmpq\nygIR0q/3w0gPGayr2qej9uq29R3sa2bWq9Qdx5qtyvqbqu3v7+L32l71uhl4nRSUzXXa6+1rZtar\n5H1AoAhPSZoSEY8B04FHgRXAlZIGk1Z9PZx0Y6sVmJG9Px1YFhHrJW2RdAjwAumabCk3r3yjyqzv\nK/PnvDuD9UJgvqS9gOeA+yJim6SbgGWkyxKXRsQmSXOBBZKeALaQblgBzAIWAgNJowKWd2P9Zma5\nNFUqfXeRAEmjgDUtLS2MHOlxqWa2w9rfvsFl81rZsHELzXvvxZxZE/nj4fvmO3btWqZOnQowuqPp\nU/NOwmJm1qdcNq+VV9dtYvNb23l13SZmz2st7LMdrGbWL23YuKXm9u5wsJpZv9S89141t3eHg9XM\n+qU5syZy4LDBDNpzAAcOG8ycWRML++zuHBVgZtZr/PHwfbn9S9NK+Wz3WM3MCuZgNTMrmIPVzKxg\nDlYzs4I5WM3MCuZgNTMrmIPVzKxgDlYzs4I5WM3MCuYnrzrgVVrNbHe4x2pmVjAHq5lZwRysZmYF\nc7CamRXMN6864BtVZrY73GM1MyuYg9XMrGAOVjOzgjlYzcwK5mA1MyuYg9XMrGAOVjOzgnX7OFZJ\nPwXWZ5trgCuBO4AK8CxwbkRsl3QmcDawFZgTEYskDQHuBoYDG4DTIuKVbj4FM7OaurXHKmkw0BQR\nU7Kv04HrgdkRMRloAk6UNAI4H5gITAOukjQIOAd4Jtv3TmB2d9ZvZpZHd/dYjwT2lrQk+96XAOOA\nx7P3HwI+CGwDWiNiM7BZ0ipgDDAJuKZq38u6sXYzs1y6O1g3AtcCtwDvJIVjU0RUsvc3AMOAocC6\nquM6am9rMzPrVbo7WH8FrMqC9FeSXiP1WNs0A6+TrsE212lvayucJ7o26/sefPR5bl30i7e3z/ro\nn3HC5HcW8tndPSrgDOA6AEl/ROqBLpE0JXt/OrAMWAFMljRY0jDgcNKNrVZgRrt9zcy6rDpUAb7x\n4C862bPrurvHeitwh6QnSKMAzgBeBeZL2gt4DrgvIrZJuokUnAOASyNik6S5wILs+C3Ayd1cv5lZ\nXd0arBHRWRj+RQf7zgfmt2vbCJxUTnVmZsXwAwJmZgVzsJqZFczBamZWMAermVnBHKxmZgXzYoJm\n1i+V+dCPe6xmZgVzsJqZFczBamZWMAermVnBHKxmZgXzqAAz65cW/2gNX/v2029vn//JMRw/fnQh\nn+0eq5n1S9WhCnDTvU93smfXOVjNzArmYDUzK5iD1cz6pfM/Oabm9u5wsJpZv7R67c5L5v36peKW\n0HOwmlm/9C+tv95p+8Glv+5kz65zsJqZFczBamZWMAermfVLw/bZo+b27nCwmlm/dMShw2tu7w4H\nq5n1S8cccdBO2xOPPKiTPbvOwWpm/dLfL1y50/Y1d63sZM+uc7CaWb9UqdTe3h0OVjOzgjlYzcwK\n1nDzsUoaAPwjcCSwGfh0RKzq2arMzHZoxB7rR4HBEfE+4AvAdT1cj5nZThoxWCcBDwNExJPAe3u2\nHDOznTVisA4F1lVtb5PUcJc0zKzvasRgXQ80V20PiIitPVWMmVl7jRisrcAMAElHA8/0bDlm1oje\n9+f719zeHY34K/QDwPGSfgQ0AacX/Q2+d92JRX+kmfUyl5wxubTPbrhgjYjtwKyersPMrDONeCnA\nzKxXc7CamRXMwWpmVjAHq5lZwRysZmYFc7CamRXMwWpmVrCGG8faRQMBXn755Z6uw8z6kKpMGdjR\n+309WA8CmDlzZk/XYWZ900HA6vaNfT1YfwxMBl4CtvVwLWbWdwwkheqPO3qzqVLkClpmZuabV2Zm\nRXOwmpkVzMFqZlYwB6uZWcH6+qiAuuotpy3pBOBLwFbgtoiY3yOF1pHjPP4SuIB0Hs8An8nmtu1V\n8i5vLukbwO8i4gvdXGIuOf4+jgKuJ03W/jJwSkRs6olaa8lxHjOBC0mjbm6LiLk9UmhOkiYAV0fE\nlHbthf6cu8daYzltSXsCNwAfBP4COEvSO3qkyvpqnccQYA5wbERMBIYBH+mRKuuru7y5pLOBI7q7\nsC6q9ffRBMwHTo+ItlWHD+6RKuur9/dxLXAcMBG4UNJ+3VxfbpIuAm4BBrdrL/zn3MFaezntw4FV\nEfH7iNgCPAG8v/tLzKXWeWwGjomIjdn2HkCv6x1lai5vLukYYALw9e4vrUtqncdhwGvA5yQ9Duwf\nEdH9JeZSb7n5p0n/ox5M6n335vGbq4GPddBe+M+5g7X2ctrt39tA+kfUG3V6HhGxPSL+E0DSecC+\nwA+6v8RcOj0PSQcBlwN/0xOFdVGtf1cHAscAXyP19qZK+kA315dXveXmnwVWAv8GLIqI17uzuK6I\niG8Db3XwVuE/5w7W2stpt3+vGeit/3BqLgsuaYCka4HjgY9HRG/tWdQ6j5NIofR90q+lJ0v66+4t\nL7da5/EaqYf0XES8ReoRtu8J9hadnoekMcCHgdHAKGC4pJO6vcLdV/jPuYO19nLazwHvlLS/pL1I\nvx78a/eXmEu9ZcG/Tvp17aNVlwR6o07PIyJuiohx2Y2HrwD3RMQdPVFkDrX+Pl4A9pV0aLY9mdTj\n641qncc64E3gzYjYBvwW6LXXWGso/Oe83z/SWnXXcww7ltN+D7BvRHyj6m7hANLdwn/osWJrqHUe\nwE+yr2XsuAZ2Y0Q80AOl1lTv76Nqv78G3tUAowI6+3f1AdL/HJqAH0XEZ3us2BpynMcs4AxgC+ka\n5pnZdcpeSdIo4JsRcbSkkynp57zfB6uZWdF8KcDMrGAOVjOzgjlYzcwK5mA1MyuYg9XMrGD9fhIW\na1ySKhHR1Ml7M4FPRMSJ2fb/II3BPCUiFmZtV5GGCb0EEBHzuqVw6/McrNZXPUKaWKPNNGBJ9ufC\nrG0ycHFEtHZzbdbHOVit4UkaSQrLfYDtwPkR8aSkVyUdFhG/IgXqbOC+bHapQaTJUJZL+jJARHxZ\n0kvAfaTJR7aSer1rJL0I3JV9zj7AX0XEyuzpqbnAAcBG4LyIeErSHVnbocBFEfG9bvhPYb2Er7Fa\nX/Ap0gQg7wUuIoUiQAswMZs2cXRErADWkOYWnUB64mlru88aAbRExFhgKTtP+PJaRIwH5gGXZG0L\nSMH5HuAs4Jvt9j/codr/uMdqfcEPgfsljQX+hTRrFKTLAR8mXUNdmrX9AJhC7Rm+Hs7+fJadp4+r\nbv+YpH2Bo4DbJbXts6+kA7LXy3fxfKzBucdqDS+7RvpnwGLgk0BbD/ExYDxpAuMlWdsSUm91clVb\n+89rm6u2Qno+vk379oHApoh4d9tX9tm/y/Z7c7dOzBqWg9UanqRrgFMjYgHpV/f3AETE70nh9iFS\nrxbSZDTvAg6KiOd35/tGxDrgeUmnZHUcz46esfVjDlbrC24GPi7pZ8ADwDlV7z0G/FdEvAZp0m9g\nFfBkQd97JvBpSU8DVwGf7MVz3Vo38exWZmYFc4/VzKxgDlYzs4I5WM3MCuZgNTMrmIPVzKxgDlYz\ns4I5WM3MCuZgNTMr2P8HyZkk6d6Uu6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146b375588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='IsWinner', y='SellerFeedbackCount', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146f18f710>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAE8CAYAAACW3un4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQaoJJVkgEpSSQaoJJX0/wHUApmQ2p7MTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146b008278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='IsWinner', y='ListingPrice', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146ee7fc50>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAE+CAYAAAAEWDLsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146b4510f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='IsWinner', y='ShippingPrice', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146b488c18>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAE8CAYAAABJkJPnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146f1e96d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='IsWinner', y='ShippingTime_minHours', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146add84a8>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAE8CAYAAABJkJPnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlpJUwLCUpAL/H6o/fqiFGI7qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146d5e9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='scatter', x='IsWinner', y='ShippingTime_maxHours', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Discuss what you observe from the scatter plots and correlations, e.g., which continuous features seem to be better at predicting the target feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. From the above plots we can see that in order to be a winning offer an offer must have a Seller Feedback Rating above (approx 90) and Listing Price must be under (approx \\$1000) however cases within these bounds are not always Winners. While Shipping Price must be under (approx \\$90) in order for an offer to be a winner. \n",
    "\n",
    "2. If we look at the correlations between continuous features, we can see that Seller Feedback Count is the only feature which has a positive impact on Seller Feedback Rating, while Shipping Price, Shipping Time Min and Shipping Time Max are the features which have a positive impact on Listing Price. \n",
    "\n",
    "3. In addition to that we can see from the scatter plots that winning offers only occur when the Shipping Time is low. \n",
    "\n",
    "Note: What we see here are not black and white relationships - there is no one or two features that have a cut off point between winning offers and non winning offers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a subset of continuous features you find promising. Justify your choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above analysis I think that the most promising fatures are Seller Feedback Rating and Listing Price. \n",
    "The results of Shipping Time Max are very similar to Shipping Time Min so I believe there is an overlap of information here. \n",
    "\n",
    "I am choosing these features because they have the strongest correlation between themselves and the target feature. I am limiting it to a small subset because after much initial testing I was unable to get an effective model predicting a positive case with a larger subset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 For each categorical feature, plot the pairwise interaction with the target feature (barplots or stacked barplots). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#define our categorical features\n",
    "categorical_features = ['IsFeaturedMerchant',\n",
    "                        'ShipsFromCountry', 'ShipsFromState']\n",
    "\n",
    "categorical_columns = df[categorical_features].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwkAAAG+CAYAAADYy0hoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYXGX5//H37iZBA6H3GkC4pRhKIISOiIACIoqCFCv4\npQmiqIggCioqUkQQkA4/QBQEEUVQesfQpHnTmxRLqCYQkt3fH+dsMmfZDUvImdls3q/rypXZM3Pm\nfmZ2dvd8zlNOW1dXF5IkSZLUrb3VDZAkSZI0sBgSJEmSJFUYEiRJkiRVGBIkSZIkVRgSJEmSJFUY\nEiRJkiRVDGl1AyRpIIiIy4ErMvPY8usVgQR+nJnfLrctDDwDLAScDxyQmQ+0qMkVEfEEsH1mjpvB\n/UcARwNjgc7y3wmZeWp5/27AsMz85ds8T78e18t+WwEHA8Mp/jbdD3wtM5+JiM9TvLate9nvVODX\nmfnXd1LvnYqItYALM3NkL/c9AbwBTGzY/GxmfrTONklSnQwJklS4HNgUOLb8ehvgD8DHgG+X2zYF\nbsrMl4HBdgD4Y+A1YFRmdkXE4sCtEfFUZl4JbADc14/n6e/jpiprnQWMzswny23fAX4DrDe9fTNz\nt3dSq0Y7z2hAk6SByJAgSYXLge9FRHtmdlKEhIOAX0fEcpn5GPAh4I8w7cw9MBfwQ+AxYFVgDmDv\nzLwmIs4EXgE+ACwF/APYMTNfi4iVgJ8DCwAdwHGZeXpEbFJu/x8wJ7ARcCqwAsXZ/TuA/yvb2NPe\nEbFa2Yajyuc7Bfh3Zh5UtntnirPy2/XYdzHgBWAoMCkzn42ITwDjI2I7irD04YiYCFwInAwsAiwK\nPAl8Gli/8XGZeUJ5sP9JiuGtTwB7ZeazPWovCAwr38tuxwJ3N7YvIv4ILA1MBnbKzAcj4lrgeGAc\ncB1wLbAa0Absk5k3RMT3gFXKti5SPu9umflKRCxR7r90+dp/nZk/Kt+rPYH9gZeBe3t5v99W+Tm5\nDRhF8Xl6qKy3ANBF8X06u/y+HwE8W7Z1AnAosC8QwEWZuf+MtEGSZoRzEiQJyMyHgfHAqIiYj+LA\n7FbgT8C25cOmhoQe1qE42FsDOA34XsN9o4EtgZWAxYFPRcQQigPtAzNzNLAxcEBEjC33WRX4TGau\nRnHQPSIzVwfWLu9fro+XMTEz1wQ+DPw4IlYBTgA+X9YE+D/gpF72/V75+v4TEX+OiEOAVzLzscy8\nGLgUOCYzTwB2BG7JzHXLtkwAdu35uIj4LEVAGlO2/08UgaciM/8OnALcFREPlMFmG+CKhoctB+yX\nmR8ArgcO6OU1LE0xZGx14EDggogYWt43liLUvZ8iZHy33H4OcHr5fRgDbBYRn46I1cv3ZKPMXBuY\n1Eu9RudGxN0N/1ZvuO++zFyJomfqUuAXmTkK+Ajwo4hYt3zc2sAPMvP9FIHt28BWwJoUAXDxt2mD\nJM00hgRJmuZyYBOKg7e/lGfrLwM2j4iRAJn5YC/7PZmZ3We97wTmb7jvz5n5Rma+SXE2en5gRWB5\n4PSIuJviDPh7gTXKfZ7uHnYD3AisUp4xPxA4NjMf6aP9J5dtfJbiAPtDZbseB7Yqey8WB67suWN5\noB7AB8v71wP+HhHb9PLYnwM3R8TXgF9ShJq5ej4O2Jri4Hxc+Tq/UtZ4i8z8OkVvxiEUY/uPBK6L\niI7yIbc3vO67gYV7eZoXM/O88vkuB6ZQnMEH+G1mvlB+T08DtoiIOSkC2uFl+26lCBqrUwSmKzPz\n+XL/X/XW7gY7Z+bqDf8ae0FuKP9fEXhPZv6ubOOzwEUUIRLg8cy8q7z9KHBNZk7KzP9Q9Eg1fq4k\nqVYON5KkaS4HdgNeBy4pt11NcZZ7M3rvRYDqhNUuiqEu07uvA3ipPOMNQEQsQjGsZSzF3AAAMvPx\niHgfRXjZFPhrRHwlMy/spR1TGm63AW+Wt08Avkgx1OVXmdnVuFPZy/BLip6NOyiGNB0dEQdT9Dz8\nocfjf0Jx1v104BqKYTqNr7lbB/CTzDyx3G8OYL6eD4qIjwELZOYZFAfNF0XEQcDTTAtObzbs0vM9\n7ja5x9ftTHtPJveyvaN8nvUyc0LZlgUpvv9f7lGj53O/E93fz95OzLVTvH9QTH5u9CaS1CL2JEjS\nNNdQnEXemHKoS3nweCewD32HhHcqgdcjYheAiFiKYrLv6J4PLMfFn0FxVvtbZbtW7eN5P1/uszTF\nkKOryu0XUhxsf5LiwL7amMzJFGe5D+kenlMGh+UpXjsUB8ndB7NbUPRonAP8q6zV0cvjrgB2i4i5\ny68Poxje09OrwBERsXLDtmUpDtYf7eO19mahiNiybP82FAfZ3XMJto2IeSKiHdgd+ENmvkLRe/C1\ncp95gZsohpf9haIHacly/8+/g3b0JYFJ5VyP7gnbnyxrSdKAYkiQpFJmTqQ4257lCkbd/kgxcfja\nmVRnEsWB6G4R8XeK4T2HZOZNvTz8bIoD8AciYhwwN8XE5t68JyLupBj7/5XMfKih3oUU8wj+08e+\n2wPzAA9FxP3A34HnKA7soehl2Tcivl1u+1lE3AH8jmJI1Pt6edypFMO1bi2fcxS9HGxn5jUUIeys\niHg4Ih4sX+O2mfliH+3tzevArhFxD/Ad4OOZ2d2T8EL5vjxI0WPzo3L7TsDYiLiXYoLx+Zl5bmbe\nC3wTuKp839/zDtrRq3LI2ceB/crv+1+Bw8rXL0kDSltXV9fbP0qSNMsqx97fAOyZmbe1uj11KOeM\n3JeZb5kbUa5utGBm7tPsdknSrMqeBEkaxCJiC4qx/VcP1oAgSZr57EmQJEmSVFHr6kYRsQ7Fyhab\nlKtznEmxKsV9FBcb6oyI3SlWz5hMsT70ZXW2SZIkSdL01TbcKCK+STFprXuy19HAwZm5IcWycttG\nxKIUV5Ncn2K1jCPKJfIkSZIktUidPQmPAp9g2nJ3oykuGATF6hebU6xTfVNmvgG8ERGPUKx+8be+\nnrQMEWtTrLoxpa/HSZIkSepTB8VFLP9WHotX1BYSMvOi7iuUltoaLuDzKsVSe3NTLEVHj+3TszbT\nrl4pSZIkacZtSLGUdUUzr7jc2XB7BPASxWXmR/SyfXqeAzj33HNZdNFFe33APpcdPMONPH7rH8zw\nvrNb3d1+OOPX/zn1Ox+e4X1bWdu6A79uK2u/m7qz28/x7Pj7Y3b7GzEr1m1l7Vmxrr8/mle7ju/x\n888/z8477wzlsXVPzQwJd0XEJpl5LfARiiub3g78MCLeA8wBrEQxqXl6pgAsuuiiLLnkkr0+YNh8\n753hRvb1nP0xu9UdOnz+ltRtZW3rDvy6raztz/HAr9vK2rPb34hZsW4ra8+Kdf390bzaNX+Pex2+\n38yQ8HXglIgYRnHFywszc0pEHEcxfKgd+E5mvt7ENkmSJEnqodaQkJlPAGPL2w8BG/fymFOAU+ps\nx2A38fYtZ3znHWZeOyRJkjQ4eMVlSZIkSRXNHG4kSZKazN5madbXip9jQ4IkSZrpDCfSrM2QIEkD\ngAdUkqSBxDkJkiRJkioMCZIkSZIqBuVwI7vtJUmSpBlnT4IkSZKkCkOCJEmSpIpBOdxIkqSBxqGw\nkmYl9iRIkiRJqrAnQZIkaRZmL5XqYE+CJEmSpApDgiRJkqQKQ4IkSZKkCkOCJEmSpApDgiRJkqQK\nVzeSJEmDxrta6Qdc7Ucq2ZMgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSp\nwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnC\nkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQ\nIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAg\nSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJ\nkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmS\nJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKliSDOLRcRQ4CxgJDAF2B2YDJwJdAH3AXtnZmcz2yVJkiRp\nmmb3JHwUGJKZ6wGHAT8EjgYOzswNgTZg2ya3SZIkSVKDZoeEh4AhEdEOzA28CYwGrivvvxzYrMlt\nkiRJktSgqcONgNcohhr9A1gQ2BrYKDO7yvtfBeZpcpskSZLetYm3bznjO+8w89ohzQzN7knYH7gi\nM1cEVqOYnzCs4f4RwEtNbpMkSZKkBs0OCS8CL5e3xwNDgbsiYpNy20eAG5rcJkmSJEkNmj3c6Bjg\n9Ii4gaIH4SBgHHBKRAwDHgQubHKbJEmSJDVoakjIzNeAT/dy18bNbIckSZKkvnkxNUmSJEkVhgRJ\nkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmS\nJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIk\nSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJ\nFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkVhgRJkiRJFYYESZIkSRWGBEmSJEkV\nhgRJkiRJFYYESZIkSRWGBEmSJEkVQ1rdgMFk4u1bzvjOO8y8dkiSJEnvhj0JkiRJkioMCZIkSZIq\nDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgwJkiRJkioM\nCZIkSZIqDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgwJ\nkiRJkioMCZIkSZIqDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgwJkiRJkioMCZIkSZIqDAmS\nJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKoY0u2BEfBv4GDAM+CVwHXAm0AXcB+ydmZ3NbpckSZKk\nQlN7EiJiE2A9YH1gY2Ap4Gjg4MzcEGgDtm1mmyRJkiRVNXu40RbAvcDFwB+Ay4DRFL0JAJcDmzW5\nTZIkSZIaNHu40YLAMsDWwLLApUB7ZnaV978KzNPkNkmSJElq0OyQ8F/gH5k5CciIeJ1iyFG3EcBL\nTW6TJEmSpAbNHm50I7BlRLRFxOLAnMBV5VwFgI8ANzS5TZIkSZIaNLUnITMvi4iNgNspAsrewOPA\nKRExDHgQuLCZbZIkSZJU1fQlUDPzm71s3rjZ7ZAkSZLUOy+mJkmSJKnCkCBJkiSpwpAgSZIkqcKQ\nIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAgSZIkqcKQIEmSJKnCkCBJkiSpwpAg\nSZIkqcKQIEmSJKmiXyEhIraquyGSJEmSBob+9iT8tNZWSJIkSRowhvTzcY9GxOnAbcDE7o2ZeXYt\nrZIkSZLUMv0NCf8F2oCxDdu6AEOCJEmSNMj0KyRk5hcAImK+zHyx3iZJkiRJaqV+hYSIWA24ABge\nEWOB64FPZ+addTZOkiRJUvP1d+LyL4DtgP9m5rPAnsBJtbVKkiRJUsv0NyQMz8wHu7/IzL8Ac9TT\nJEmSJEmt1N+QML4cctQFEBE7A+Nra5UkSZKklunv6kZ7AmcBq0TES8DDwC61tUqSJElSy/R3daNH\ngQ0iYk6gIzNfqbdZkiRJklqlv6sbrQEcBMwPtEUEAJm5aX1NkyRJktQK/R1udDZwMnAf5bwESZIk\nSYNTf0PChMw8vtaWSJIkSRoQ+hsSroiIrwBXAK93b8zMp2pplSRJkqSW6W9I2LX8/2sN27qA5WZu\ncyRJkiS1Wn9XN1q27oZIkiRJGhj6u7rRMsA+lKsbdW/PzC/W1C5JkiRJLdLf4Ua/AW4o/7m6kSRJ\nkjSI9TckDM3MA2ptiSRJkqQBob2fj7sxIraJiGG1tkaSJElSy/W3J2F7ijkJdF9tGejKzI46GiVJ\nkiSpdfq7utHidTdEkiRJ0sAw3ZAQEV/OzF9FxHd7uz8zD6unWZIkSZJapb/Djdre/iGSJEmSBoO3\nCwmLR8S6wOGZ2dmMBkmSJElqrbcLCcOAnwIrRMTNwF+AKzPz0dpbJkmSJKklphsSMvMggIiYA1gH\n2BA4PiIWA27JzD3rb6IkSZKkZurXdRIy8w3gJeA14EWgE5i/xnZJkiRJapG3W93oM8AWwAeBx4C/\nAscA4zKzq/7mSZIkSWq2t5uTcC5wBfDJzBzXhPZIkiRJarG3CwkfoOhJ+GFEjASuB64E/pqZL9bc\nNkmSJEktMN05CZl5f2YenZlbAKsBF1JMYL4hIm5rRgMlSZIkNVe/LqYWEe8D1gc2AMZQTGC+tr5m\nSZIkSWqVt5u4fAkwFvgPcDXwR+AbmflSE9omSZIkqQXerifhN8Aemfl8MxojSZIkqfXe7mJq5wFE\nxBiKoUbHA5cBa1CEh4tqb6EkSZKkpurXxdSA44BxwPbABGBN4MC6GiVJkiSpdfobEtoz83pgK+Ci\nzHyafk56liRJkjRr6W9ImBARXwc2BS6LiP2AV+trliRJkqRW6W9I2BmYk+LKyy8CiwM71dYqSZIk\nSS3TryFDmflP4LCGr79VW4skSZIktdTbXSehE+jq5a42oCszO2pplSRJkqSWebslUPs7HEmSJEnS\nIGEIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJU\nYUiQJEmSVGFIkCRJklRhSJAkSZJUMaQVRSNiYeAO4MPAZOBMoAu4D9g7Mztb0S5JkiRJLehJiIih\nwMnAxHLT0cDBmbkh0AZs2+w2SZIkSZqmFcONfgacBDxbfj0auK68fTmwWQvaJEmSJKnU1JAQEZ8H\n/p2ZVzRsbsvMrvL2q8A8zWyTJEmSpKpmz0n4ItAVEZsBqwNnAws33D8CeKnJbZIkSZLUoKk9CZm5\nUWZunJmbAHcDnwUuj4hNyod8BLihmW2SJEmSVNWS1Y16+DpwSkQMAx4ELmxxeyRJkqTZWstCQtmb\n0G3jVrVDkiRJUpUXU5MkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAk\nSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJ\nklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmS\nVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJU\nYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRh\nSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFI\nkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQ\nJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVGFIkCRJklRhSJAk\nSZJUYUiQJEmSVGFIkCRJklRhSJAkSZJUYUiQJEmSVDGkmcUiYihwOjASmAP4AfAAcCbQBdwH7J2Z\nnc1slyRJkqRpmt2TsAvw38zcENgSOB44Gji43NYGbNvkNkmSJElq0OyQ8FvgkPJ2GzAZGA1cV267\nHNisyW2SJEmS1KCpw40y8zWAiBgBXAgcDPwsM7vKh7wKzNPMNkmSJEmqavrE5YhYCrgGOCczzwMa\n5x+MAF5qdpskSZIkTdPUkBARiwBXAt/KzNPLzXdFxCbl7Y8ANzSzTZIkSZKqmjrcCDgImA84JCK6\n5ybsBxwXEcOABymGIUmSJElqkWbPSdiPIhT0tHEz2yFJkiSpb15MTZIkSVKFIUGSJElShSFBkiRJ\nUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElS\nhSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKF\nIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUh\nQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElSxZBW\nN2Bmmjx5Mp2dncwzvGOGn2PSpEkzvO9gqtve3s6QIYPq4yFJkqR+GjRHga+++iodHR0MGTKEQ760\nTkvaMJjqTpo0iYkTJzJixIiZ/tySJEka2AZFSJg8eTIdHR0MHz4cgPaOoTP8XMOGDZvhfQdT3WHD\nhjFhwgQmT55sj4IkSdJsZlDMSejs7PRAtgYdHR10dna2uhmSJElqskF5ZD2lcwpPvfr4DO3bNXzu\nXrcvP9/ydLTP+Nj/WVFbW1urmyBJkqQWGJQh4alXH2eLi9aeqc+Z+yQrLrBin/d/7nOf41O7fJl4\n/yq8+eab7PzJLdhh5y/wyR12BeDAr+3JsGHDOOTwnzF06IwPD5IkSZLqNiiGGw0E66+/PvffezcA\n9997N2uuNZZxt98MwKRJb/Dvfz3H94841oAgSZKkAW9Q9iS0wnrrrceRR/2cT3xqZ8bdfjObf/Rj\nnHnKCfzvtdd49JF/sOqoNfnSLttx0hkXcMKxP2Ho0KG88PxzvDj+v3z1m4ewwlJj2XzzzVlzzTV5\n/PHHWWCBBfjFL35BZ2cnhx56KE8++SSdnZ189atfZZ111mHrrbdm5MiRDB06lL2+dmirX74kSZIG\nEXsSZpKVV16ZZ55+kq6uLu7/+118YNSarL7m2tx95+3ce8+drLn22MrjF15kMQ7/yXFs/fFP8ec/\nXgLA008/zX777ccFF1zA+PHjuffee/ntb3/LfPPNx7nnnssvf/lLDjvsMAAmTJjAXnvtxTHHHNP0\n1ypJkqTBzZAwk7S3t7Pscitwx99uYd75F2DosGGMHrMeD9z/d+6/7x7WHF29lsFy7yvmNyy00CK8\nWV7QbL755mOxxRYDYLHFFuONN97goYce4vrrr2fXXXdl3333ZfLkyYwfPx6AZZddtomvUJIkSbML\nhxvNRKuPHsNvzjuTjT+4OQArr7oa559zGm1tMGLueSqPbeOtKwf1tprQcsstx6KLLsoee+zB66+/\nzoknnsi8884LFMFEkiRJmtk8ypyJ1hg9hgfuu4e11lkPgKFDhzLXXHOx6qg1Z/g5d9xxRx577DF2\n2WUXdtxxR5ZYYgnDgSRJkmo1KHsSlh6xLFd88m8ztO/Ixfq+TsLbWXiRxbjsr7dVth182JFTb59+\nbjH3YP9vfnfqttFj1mX0mHUBuOmmm6Zub5xr8NOf/vQtta6++uq3bY8kSZI0IwZlSOho72DZed43\nQ/uusMC8M7k1kiRJ0qzFcSuSJEmSKgwJkiRJkioMCZIkSZIqDAmSJEmSKgblxOUpU+CpJ2cs/3RN\n7H378stDR8e7aJQkSZI0ixiUIeGpJ9vZYpPelzKdUZmw4op933/bbbexxx57csKp57PQwosAcOYp\nJ7Dk0suw2RZb97rPq6+8zB1/u5VNPrTF1G3jxo3j5JNP5pRTTgHg5JNP5rTTTuPmm29myJAh3Hbb\nbZx11lnsuOOOPPfcc+ywww4z70VKkiRJONxopho6bBjHHnk4XV1d/Xr84489wm23XF/Zttpqq5GZ\ndHZ2AnDjjTcyduxY7rzzTqAIIxtuuCEbbbSRAUGSJEm1GJQ9Ca0yavXRdHV2cdnvL2Sbj3+qct/v\nfnsuN1zzF9o7Olh11Bp8Yfd9+M15Z/L4Yw/z58suZoU9vwAUV2leeeWVyUyWWGIJOjs7+ehHP8q1\n117LmDFj+Nvf/sYRRxzB7373Ox577DF23HFHvv6V/VhooUV47rlnWDFWYe+vfotzzzqFF55/lpdf\nepF/vfAcu+25P6PXHsu999zJOaefSHtHB4sutgTHHvVj/vCHP3DRRRfR2dnJvvvuy7rrrtuKt0+S\nJEkDhD0JM9le+32L3190Ps/+8+mp25547BFuvO4qjjzuVH523Kk8+8+nuf3WG/n0Tp9n1Oqj2XLr\n7SrPsd566zFu3DhuvPFG1ltvPdZff31uvvlm3njjDV555RWWXHLJyuOffeYp9j3gOxx9/BmMu/1m\nXhz/X6AIHN8/4li+vPfX+P1F59PV1cUvjv4RB33vJ/z46JNYYMGFuPjiiwGYe+65Of/88w0IkiRJ\nsidhZpt7nnnYfa/9Oeanh7HSKqMAeObpJ4mVVmHIkOLtXmXV1XnqicdY8f2r9Poc66+/PscddxzD\nhw9n5513ZsSIEYwYMYIbbriBMWPGvOXxiy2xFMOHzwnA/PMvwKRJbwCw/PsCgAUXWoRJkybx8ksv\n8uL4//Ljw78DwKRJbzDfiDlYZpllWHbZZWfuGyFJkqRZlj0JNVhn3Q1ZYsmluerKPwKw5FLL8NCD\n9zNlymS6urq47967WHzJpWlvb6er863zF5Zffnn+9a9/8dBDD7HKKkWQ2GCDDTjttNPYcMMN3/L4\ntr4a0la9Z+555mWBhRbmkMOO5MdHn8gOO32esWPHAtDe7kdBkiRJBY8Ma/LlvfZn2LA5ABi53PvY\nYJPN+MZ+X+Zre3+BRRZZjHXX35hFF1+CJ554lN9fdP5b9h85ciQrrLACbeWB/kYbbcQDDzzQa09C\nf7W3t/MH+/HUAAAUXUlEQVTlvfbn+9/ZnwP23Y0/XnoRK05vySZJkiTNlgblcKOll+nkimtfmaF9\nRy7W+9Kpyy8//f3WWWcd5l88pn49fM65OOO830/9ervtd2K77Xeq7LPgggtz0ukX9Pp8RxxxROXr\nlVZaiXvuuWfq15/4xCem3j7q+NPfcnvnz+0+ddtSS4/kx0efCMCaa41lzbXGTr1vgQXmrTyXJEmS\nNChDQkcHLLtc5wztu8JSM7kxkiRJ0izG4UaSJEmSKgwJ6lN/LwonSZKkwWVQhIT29nYmT57c6mYM\nOlOmTHHVI0mSpNnQoJiTMGTIECZOnMiECRPo6Oigc8qbM/xckyZNmuF9B0vdrq4upkyZwpQpU6Ze\n20GSJEmzj0FzBDhixAgmT55MZ2cnh5922ww/z+mHbD7D+w6Wum1tbQwbNsyAIEmSNJsaEEeBEdEO\n/BJYDXgD2C0zH3mnz9N9UPvyhCkz3JZhw4bN8L6zW11JkiQNTgNlwPnHgfdk5rrAgcBRLW6PJEmS\nNNsaKCFhA+DPAJl5K7BWa5sjSZIkzb4GxHAjYG7g5Yavp0TEkMzsbcmiDoDnn3++zyd7c8L4GW7I\nM888M8P7Wrc5dVtZ27oDv24ra1t34NdtZW3rDvy6raxt3YFft5W166jbcCzd0dv9bQNhLfyIOBq4\nNTN/U379TGYu2cdjNwBuaGb7JEmSpEFqw8y8sefGgdKTcBOwDfCbiBgL3Dudx/4N2BB4DpjxGbuS\nJEnS7KsDWIzi2PotBkpPQvfqRqOANuALmfmP1rZKkiRJmj0NiJAgSZIkaeAYKKsbSZIkSRogDAmS\nJEmSKgwJkiRJkioMCZIkSZIqBnVIiIiOiPhERGwQESMi4pSIODMiRra6bYNNRLS1ug0DRURs2KK6\nY1tRV5LUPxGxRKvboMGpjs/WQLlOQl3OolhSdW5gSeBS4GngdGDTuotHxPyZOb68vQgwJTP/U3fd\nXtqxKrBPZu5RY5mraMJ72lNEtGXmW5boiohlMvPJZrendBQwphmFImIOYCdgH2AOYNVm1O3RhnMy\nc9can/89wP8BxwFLAMcCrwMHZGbfl15/93WHAT8CPknx3r4KXAAc1sfV4Gdm7RX7ui8zH6q59jLA\n54FlgKeAMzPziTpr9tKG9YBhmXltzXXOAHpd4i8zv1hz7S/32NQF/Au4PDMn1Vj3bOBXvV04qU4R\n8X+ZeXIza5Z1l+7rvsx8qont+CDF7+n1gUWbUK8lxx+tqBsR3+3rvsw8rMa6H8jMt1zXKyJ2ycz/\nV1fdXurV9tka1D0JwHKZuTPwcWB4Zh6amacCnXUXjoiNgbsiYr5y02rAHeUVo2tX9qJ8KiKuAy4E\nHmlG3Ra4qvtGRBzZsP2MFrSlW+29KhExsny9DwOHAV/JzKYHhO7m1Pz8x1EcsLYDJwB3AxcBJ9Zc\n9yhgPLBSZi4OrEXxvf1ZzXUBTgZO6uNfbSJiDHAZ8Dzwa+DfwGURsU7NdXeOiOcj4oGIOJTi9R8e\nEcfUWZfiNV5Q/hvdcPuCmutCcQGjxn+LAx9tQu3fAd+MiHsiYr+ImLfmet0+HBGXRMT8TarX7QKq\n3+dfA+MofnfWKiLmjIi9I+I+4LcUf4uXaULdlhx/tPC454Ue/14D9ga2qrnuGRHxue4vImJ4RJwF\n7Flz3aZ9tgZ7T8LrAJk5JSL+2bC9GeHoB8DGmfli2YYrI+LDwGkUV4yuRUQsSnHWdVfgFmCOzHx/\nXfUarBIR5/V2R2buVGPdxgPy0X1sb7ZaLz4SEZcC8wDnUPQcXJCZN9dZs8VWycz1yx6FDYHtM/PN\niPh6zXVHZ+Z63V9k5qvAIRFxbc11AZ6g+Bz1/BzXfWGbw4GtGs6wXhkRl1MctH+4xrpfBVak+Fzf\nTfHH7n9ArWe7M/OK7tsRcWDj13XLzO/3tj0ibqq57iXAJeVZ3s8CV0fE/cDJdfYuZOb2EbEjcE1E\nfCMzr6yrVo+663bfLnsHDwPmAj5SZ92I+AVF7/rFwHbAcZl5fp01G7Tk+KNVdRt7qCJifeBU4HiK\nnuA6bQKcFhEbAadQvM6LgLp7IZv22RrsIWGBiNic4g9t4+1mnMmY3LOLPjMfioi6ezEeAX4OrJmZ\nr5R/4JvhWYoDiVZqPKCq/SqBEXFLL3XagGaEssnAeykCb1OuiFj+/PTUPZyvTq+W/68P3J6Zb5Zf\nv7fmum/0sb32nkhgTWA4cC5wM80LvcN6DsHIzMfKYW11+l9mvgK8EhH3ZeZrABHR1/egDi29smhE\nvBf4FlDbUKNGmfkCcGREHAccAvwVeE/NNX8dEfcAt0TEBIrPdVfZU1eriFgNOJPida6dmXV/tjYA\n7gBuAx6luZ+vVh1/tKouETGUIhRsBuyUmXfVXbP8PbVDRPwJuAnYIzNPqbsuTfxsDfaQcCfwmYbb\nOwIL0ZyDuPaIaM/MqT8cEdEBDKu57heB3YCrIuL0JtTr9lJmXtekWo26+rjdDH8Czi5vLwH8czqP\nnWky82MRsRTF9/o2YK6I+AhwRePnrQafoff3uO5ejNfK8dvbA+dFRDuwM8V4+Tq1lX94Gg/Q22hC\nT2RmrlbOJdoFOBC4Hvh/mVn3sMGOnhvKRQnqDgmNn9spNdcaECLisz02DaMY3vWHJtXfgKInYQPg\nEmCVJtT8InAwxfDIc+quV9ZsBw6imLv15WbNxcjMNcq5NbsDR1P8Pnl/Zv6jCeVbdfzRkroRsQbF\nEOM/A2MaTiTVKiIWoJj7OhHYHPh5OU/yV3XWbeZnq62rq6UnT5qmHGu7D8U38qLM3LvmertTJNof\nAY8BSwHfBW7NzGPrrF3WHwl8ieIg43bgnMy8rMZ6BwCvAKdn5uQoVvhZJTPrHkP9MnB/+eXKwAMU\nB3IrZWatY20j4urM3LTn7WYqw8JWwKeAFTKzz0l6M6HWLX3c1dU4LKeGuktTjC99ATiGopt1X+DX\ndXbfR8Tj9D2pdbm66vbRlo2ArwBLZWZtq1hFxCHAnMBBmdlZHmD9CHgzMw+pse4bwH/LLxcob7cB\n82VmbWe3I+I5pn2Pu+sCUPfZ7Yg4osemNuALwITMXLbGut+jOGB+mGKIxGV1T8Qv615OEbC/lJnP\n1F2voe5tFMPXfkoxVn2qug/mImJuil7fDoq/xV8q665Vc92WHH+0sO4kiuOPh5n289zdS1Xn36ZH\ngJ91H+eU83tOp5is/aka634ROD8zJ0bECGr8bA3qnoRy/OFngL0ounDnBpbNzIl1187MUyLiFYqU\ntzjFWc/TM7P2CXHlWdfTM/OQiPgLsDpF4qwtJFCM8RwL/D+KX4pPA/tHxEKZeXiNdUcB8wIHAC8D\nN1BM4mlGl33PM8xNERErA8eXoeRK4CWK1bu+VnPpHWt+/r5cBnwoM/9dfn1VRKwL/ASoc4zvtbRm\nXsBU5R+AT1D8HpuT4uerTkdQjNl+PCLGUwzN/A3Fmdg69Vzpp1vd7/WBLapLZn67+3ZELE9xRvIy\nivkZdfo8xdjppyj+Ju4UEd1tOrvv3d61yyjmmWzaXa9bzXX/VP7/Aaat2PUYNf/Ojoh9gK9T/D3c\nJzNPBE4sz3rXqsfxx3oUPZGnUcwxGp6ZE2quewzFZPwngXOb0Gt0CfCNmmv05u+NJ0Iz8yXgExFR\n99/iUcBBEXElxVyi2j5bgzokUEz+Ox/YJTMfjojLmxEQYOr4x12Ax4EfU6yoMDoihtX5A1OeJVqV\naQfrT1H80bmjrpqljwBjs1yONDOfiIgdKIai1BkSxgDfpJgP8S+KPwIXUpy9qHsJ1FYNdfoJxWsG\neD4zPxgR76OYrPXbuopm65aUPQz4U0R8CBhKMU7/DYpx+3XqOS8AmhQGI+LTFKFsGYqJcHv0HOtb\nk+4zq1cDC1P0zC1I8dmqczJezyGgbRQHsxOZNqRvMNWdKiL2pvgdvX+dvb0Nzqf4XHe/9naK1zyB\nel/zkj2+ntpzUnPdoyhe84IUf49Xphh2/Jnp7TQT7ESx8tvcFItMXAHQjLHyETGEYqLwshQLAaxK\n0QO7JUVwuK+mumtSBO91gK0pVmNbNiJeysw6h9Et2KK/T72OVsjMo+ssmplfjYhvANsCP2rowZjp\nJ80Ge0g4lmLs8siIOJXmrnhzInAoMB/FDPQ1KMab/pniF0ZdpnewXtt6wRQTDysHyuUKNK/2tcNM\nsh+wSWb+r3tDFEuQ/b78V6fREdE9qXTlhtu1dnFSLOc7rrz9MkBmPlL+YRh0MvPCcm7AXyh+nn6e\nmSc0oW6r5gVAcVLhH8A9FGdAf9RwtrfO1cLWopgQfi7FH5ym/M7s46z6H6n5rHqr6pb1lqAYRz2e\nYhz1i3XXhNb1YLSw5+THwG8beysi4kvAkRQrAdbl9Syud/GfclRDMx0KvNA9LLKcV3QqsEhm1hIQ\nSkcCn8vMSRHxA4pQ8ghwOfXOtVk+InpdySgz6+wFbVVdynkXFwIXRsTiFENwn6IIwzPNoDyo6JaZ\nPwV+GsXavbsBa0fETyjG59f5gwIwKTP/AhARX83Mh8vbr01/t3fttT4O1uuuOyEilsvMx7o3RMRy\n1H+GfXJjQADIYlWnZkx+HNWEGr2ZuqpPZn68YXtTJmu1QmaeX06A251iHHWz6t5HOSSlnBdwRETU\nOi+g9MGan79XmTmqhcGoFWfVW1n3fooesauBExqH4NQcBIHZ6r1eLTP3adyQmadFxG5NqN2t2Uty\nfzAzp16bIDO7ImJJZvIBZC86MvPv5UHrnJl5J0DUv7rRBCBrrjGQ6gJTLzS6HcUCBCOYNsJgphnU\nIaFbFqvuXFd2yexKcSa/7nGBjT8UrzfcrntllIl9HKzX/UP6LYq1t6+iGO+5NLAF8Lnp7vXu9fW6\nmrECTauG3/wzIsZk5u3dG8qJ+bVdfbiVIuJ8ps0NWB64sZww1qyDqWbPC+j+ndUSrQhGrTqr3qq6\npW2bWGuq2fC97uvkSd2TtbuvHdRGj+sINeH3Vm9/F3eg/pWzut/rLSmWmu1emnREzXWfz8yzaq4x\nYOpGxCYUx1YfpJyPUdeJ79kiJHQrJ5X8ovxXt95+QbRRjIesU0sO1jPz/nJFo20pJmrfCRyWxQWo\n6tTbRdya8T630jeBS8vv8SPAcsCHgG1a2qr6nNTH7Vq1cF5Ay7UgGLXqrHrLzua3MAjObu/1+IhY\nq2GIJhGxFkVYqdOnG2437fdWaWJELJ+ZjzZsW4Bi4nid/hrFxQCXAj5WDis7nvqvIl73nMuBVvd7\nFPPH9siar/cx2yyB2mzlEKde1f3HISLmYdrB+pMUS9zVfbDeEq18n1spigsvbUMxMe1p4Pc9h13p\n3Sm7yLvnBUDD0Llm9GC0Qi/B6LxmBKNW/RzPjr8/Zrf3OorlwC+lWK3sUYrfmZsB22Tm43XVbaWI\nGE0xYuIUipOFy1MuiV73xOmIWAl4OTOfLUPCqMy8uM6aqo8hQZJ6MZseQM52wUiDXzl2eyuKXtd/\nMhucVCmHd+0KjKSY0Hp2NvH6FBocDAmSJGD2DEaSpN4ZEiRJkiRV1L4CjCRJkqRZiyFBkiRJUsVs\ntQSqJA1GEbE98G2K3+ntFJMUj4yIJyiuSP5Ej8efCpzUuCxkP+ucCWxKdfnIP2bmd2a48b3XGQUc\nS7Fs4xDgFmC/zPxfRGwDrJCZR09n/2WBgzPzSzOzXZI0OzEkSNIsrFzF5Chgzcz8b0TMRXHxyD6v\nBJqZ7+Zqs9/NzDPfxf79cQHwxcy8JSLagROAw4GvAaP7sf8yFMs+SpJmkCFBkmZtCwJDgeHAfzPz\ntYj4HNOu9P7diFijvP+zmXlbRFxLcUEegO9TXCl1KeB2YDdgDuB8YNHux2TmpX01oFyL/s/Af8q6\nm1P0BHyIYhnVczLzJ+WVQr/DtKtnXwi8DHy83PbRzHyhrDscIDM7I+L7wMiIWBnYo6z5JHAlcBow\nL7AYcH5mHggcBywXESdk5t4RcSDFxa06gCuAb2Wmq3ZI0nQ4J0GSZmGZeQ/we+CxiLg9In4CdGTm\nI+VDHsjMNSiuNH9AL08xBtgbeD/wnvL2dsATmTka2AXYsOHxh0XE3Q3/RpTbg+JiTZtRHMgvBYwq\nn/+TEbFV+bh1gC8AqwB7Av/OzLWAv1NcyA1gf4qrij8cEb8CRmfmrZn5AMXVa0/KzDMorgh9fmaO\nLWvtFRELAvsC48qAsCVF78PawBrAEsDO7+Q9lqTZkSFBkmZxmbknxUWTTqQYanNrRHyivPuS8v/7\nKXodero+C10UV2ndFLgZ+HhEXAJsQDHUp9t3M3P1hn/dV3P/V8Pch02BMzNzSmZOAM6l6FUAuC8z\nny63/we4qtz+JDBf+XrOpOhN+CZFL8eZEXFsL6/7Z8BTEXEA8HNgGDBnj4dtRhFM7gDuBNaiCCiS\npOlwuJEkzcLKM/RzZeYFwBnAGRGxO9A9aXdy+X8XxZCeniY33G4HJmfmwxHxfmBLYBvg6xGx0ts0\nZWKP52nUxrS/N5OmU5+IWAHYMTMPBy4GLi4Dwt3AV3s89iiKq+ieRxGGNuOtr7EDOLZ7onNEzNuz\npiTprexJkKRZ2wTgiHJeABHRBqwM3NXP/TeIiCXKCcKfBS6PiH0o5iH8FtgLWBiY5x206WrgcxHR\nERHDKYb3XNPPff8N7BcRmzZsW4Vpr2cy0wLHh4Ejy3YuRTGUqKPHY64Gdo2IuSJiCEWY2P4dvBZJ\nmi0ZEiRpFpaZ11BMPr6sXNHoHxQHyof18ymeBc4GHgD+CZxafh0RcS9wPfC9zHzpHTTrZOAZ4B6K\ng/tLM/Pi/uxY1tkKODQiHouIf1DMYfhM+ZDrgZ0j4ivAEcA5EXEH8A1gHLAs8CAwb0Sck5l/AC4C\nbgPuo+iROOsdvBZJmi21dXW5wIMkzY7K1Ya+l5mbtLgpkqQBxp4ESZIkSRX2JEiSJEmqsCdBkiRJ\nUoUhQZIkSVKFIUGSJElShSFBkiRJUoUhQZIkSVKFIUGSJElSxf8HJIwUjPErZPYAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146d5df0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find unique values in ShipsFromState\n",
    "\n",
    "states = pd.unique(df.ShipsFromState.ravel())\n",
    "\n",
    "# Insert a new column called 'percent' and fill it with 0s\n",
    "df['percent'] = 0\n",
    "\n",
    "# Iterate through the unique values in State and for each value count the amount of winners\n",
    "# Find the indexes of each row with a particular state and for each of these row insert count * 100 in the percent column\n",
    "for s in states:\n",
    "    count = 1 / df[df.ShipsFromState == s].count()['IsWinner']\n",
    "    index_list = df[df['ShipsFromState'] == s].index.tolist()\n",
    "    for i in index_list:\n",
    "        df.loc[i, 'percent'] = count * 100\n",
    "\n",
    "\n",
    "category_group = df[['percent', 'ShipsFromState','IsWinner']].groupby(['ShipsFromState','IsWinner']).sum()\n",
    "\n",
    "my_plot = category_group.unstack().plot(kind='bar', stacked=True, title=\"Winners by State Shipped From\", figsize=(13,7))\n",
    "\n",
    "red_patch = mpatches.Patch(color='green', label='Winner')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Winner')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "my_plot.set_xlabel(\"ShipsFromState\")\n",
    "my_plot.set_ylabel(\"IsWinner\")\n",
    "my_plot.set_ylim([0,100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwkAAAGzCAYAAABkVVu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ4IkSZKkgiFBkiRJUsGQIEmSJKnw/wEyWgHEPtaa8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146daf3e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of female candidates\n",
    "featured = 1 / df[df.IsFeaturedMerchant == 1].count()['IsFeaturedMerchant']\n",
    "\n",
    "# Counts the number of male candidates\n",
    "not_featured = 1 / df[df.IsFeaturedMerchant == 0].count()['IsFeaturedMerchant']\n",
    "\n",
    "# Create a new column in the dataframe called percent and insert male_count in all cells\n",
    "df['percent'] = not_featured * 100\n",
    "\n",
    "# Find indexes of all rows containing value Female for Gender\n",
    "index_list = df[df['IsFeaturedMerchant'] == 1].index.tolist()\n",
    "\n",
    "# For each row with a 'female' value, insert female_count in the percent column\n",
    "for i in index_list:\n",
    "    df.loc[i, 'percent'] = featured * 100\n",
    "\n",
    "# Group dataframe by Gender and Elected and sum precent\n",
    "category_group = df[['percent','IsFeaturedMerchant','IsWinner']].groupby(['IsFeaturedMerchant','IsWinner']).sum()\n",
    "\n",
    "# Plot values of category_group in a stacked bar chart\n",
    "my_plot = category_group.unstack().plot(kind='bar', stacked=True, title=\"Winners by Featured Merchant Status\", figsize=(13,7))\n",
    "\n",
    "# Define legend colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='Is Winner')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Winner')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"Is Featured Merchant\")\n",
    "my_plot.set_ylabel(\"% Winners\")\n",
    "my_plot.set_ylim([0,100])\n",
    "\n",
    "#by looking at this - we cannot confidently say that if a product is a featured merchant that it will be a winning offer \n",
    "#but we can say that if it is not a featured merchant it definitely won't be a winning offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwkAAAG7CAYAAACIBtnbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146f2991d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of female candidates\n",
    "count_CA = 1 / df[df.ShipsFromCountry == 'CA'].count()['ShipsFromCountry']\n",
    "\n",
    "# Counts the number of male candidates\n",
    "count_US = 1 / df[df.ShipsFromCountry == 'US'].count()['ShipsFromCountry']\n",
    "\n",
    "# Create a new column in the dataframe called percent and insert male_count in all cells\n",
    "df['percent'] = count_US * 100\n",
    "\n",
    "# Find indexes of all rows containing value Female for Gender\n",
    "index_list = df[df['ShipsFromCountry'] == 'CA'].index.tolist()\n",
    "\n",
    "# For each row with a 'female' value, insert female_count in the percent column\n",
    "for i in index_list:\n",
    "    df.loc[i, 'percent'] = count_CA * 100\n",
    "\n",
    "# Group dataframe by Gender and Elected and sum precent\n",
    "category_group = df[['percent','ShipsFromCountry','IsWinner']].groupby(['ShipsFromCountry','IsWinner']).sum()\n",
    "\n",
    "# Plot values of category_group in a stacked bar chart\n",
    "my_plot = category_group.unstack().plot(kind='bar', stacked=True, title=\"Winners by Ships From Country\", figsize=(13,7))\n",
    "\n",
    "# Define legend colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='Is Winner')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Winner')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"ShipsFromCountry\")\n",
    "my_plot.set_ylabel(\"% Winners\")\n",
    "my_plot.set_ylim([0,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Discuss what knowledge you gain from plotting the interaction of descriptive categorical features and the target feature, e.g., which categorical features seem to be better at predicting the target feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Ships From State seems to be the most informative - there are a high number of winners from BC and PA. \n",
    "2. Is Featured Merchant gives some indication - there are no winners in instances where the offer is not a featured merchant.\n",
    "3. There are a higher percentage of winners respectively in the offers shipped from Canada than the US. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a subset of categorical features you find promising. Justify your choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to choose the subset of features Is Featured Merchant, Ships From BC and Ships From PA. These are the features that have the highest number of instances of the target feature. Is Featured Merchant also makes sense from a general perspective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we go ahead and train the models, we need to do something with the categorical features - so we will create dummies for them and treat them as individual features. \n",
    "\n",
    "We also need to drop the features we have decided not to include as part of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(df.columns[[4, 6, 7, 10]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ShipsFromState_dummies = pd.get_dummies(df.ShipsFromState, prefix='ShipsFrom').iloc[:, :]\n",
    "df = pd.concat([df, ShipsFromState_dummies], axis=1)\n",
    "#I know that we would normally not use the first dummy but I wasn't sure whether that was the case in a complex feature like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ShipsFromCountry_dummies = pd.get_dummies(df.ShipsFromCountry, prefix ='ShipsFromCountry').iloc[:, :]\n",
    "df = pd.concat([df, ShipsFromCountry_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IsWinner', 'IsFeaturedMerchant', 'ListingPrice',\n",
       "       'SellerFeedbackRating', 'ShippingPrice', 'ShipsFromCountry',\n",
       "       'ShipsFromState', 'ShipsFrom_AB', 'ShipsFrom_BC', 'ShipsFrom_CA',\n",
       "       'ShipsFrom_CT', 'ShipsFrom_DE', 'ShipsFrom_FL', 'ShipsFrom_GA',\n",
       "       'ShipsFrom_IL', 'ShipsFrom_KS', 'ShipsFrom_MD', 'ShipsFrom_MI',\n",
       "       'ShipsFrom_MO', 'ShipsFrom_NB', 'ShipsFrom_NH', 'ShipsFrom_NJ',\n",
       "       'ShipsFrom_NV', 'ShipsFrom_NY', 'ShipsFrom_ON', 'ShipsFrom_PA',\n",
       "       'ShipsFrom_QC', 'ShipsFrom_SC', 'ShipsFrom_TN', 'ShipsFrom_TX',\n",
       "       'ShipsFrom_VA', 'ShipsFromCountry_CA', 'ShipsFromCountry_US'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now we can drop ShipsFromState and ShipsFromCountry as well as the Dummy columns for features we are not considering\n",
    "df.drop(df.columns[[4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Predictive Modeling: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Train a linear regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = ['IsFeaturedMerchant', 'ListingPrice', 'SellerFeedbackRating', 'ShipsFrom_BC', 'ShipsFrom_PA']\n",
    "\n",
    "lm = sm.ols(formula = \"IsWinner ~ ListingPrice + SellerFeedbackRating + ShipsFrom_BC + ShipsFrom_PA + IsFeaturedMerchant\", data = df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the quality of the model on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was initially assigning the predictions to a class by first creating the data frame with the actual class and predicted class and then iterating through that data frame and checking the values - but I realised that the values weren't be accessed correctly and my generalized else clause was causing everything to be put into the negative class. Below is the fix for this problem - creating a list of predictions that are converted to a binary predicted class and then creating the data frame using that list instead of the original predictions. Converting to binary was necessary because otherwise I got a 'cannot deal with mix of continuous and binary' error when trying to create the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the predictions\n",
    "lm_predictions = lm.predict(df[feature_cols])\n",
    "predicted_class = list()\n",
    "for i in lm_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_lm_predicted = pd.DataFrame({'ActualClass': df.IsWinner, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.948043069561\n",
      "Confusion matrix: \n",
      " [[5547    0]\n",
      " [ 304    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5547\n",
      "          1       0.00      0.00      0.00       304\n",
      "\n",
      "avg / total       0.90      0.95      0.92      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of winning offers:  5.4470524995520515 %\n"
     ]
    }
   ],
   "source": [
    "#Investigating the reliability of our accuracy score\n",
    "winners = 0\n",
    "for index, row in df.iterrows():\n",
    "    if df[\"IsWinner\"][index] == 1:\n",
    "        winners += 1\n",
    "\n",
    "percentage_winners = (winners/5581) * 100\n",
    "print(\"Percentage of winning offers: \", percentage_winners, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Analysis: \n",
    "\n",
    "We can see from the above that the model is not a good one. The accuracy score here is misleading because it indicates that we have 90% accuracy. However this is a false accuracy because the model is predicting everything as negative - and because the percentage of \"winners\" in the data set is only 5% the model comes through as 90% accurate. But in fact, it is a very bad model, because it is not successfully predicting any cases in the positive class - and we can confirm this by looking at the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept               0.000245\n",
       "ListingPrice            0.000003\n",
       "SellerFeedbackRating   -0.000019\n",
       "ShipsFrom_BC            0.259856\n",
       "ShipsFrom_PA            0.189775\n",
       "IsFeaturedMerchant      0.050335\n",
       "dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>IsWinner</td>     <th>  R-squared:         </th> <td>   0.082</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.081</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   104.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Apr 2017</td> <th>  Prob (F-statistic):</th> <td>1.40e-105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:10:30</td>     <th>  Log-Likelihood:    </th> <td>  755.21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5851</td>      <th>  AIC:               </th> <td>  -1498.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5845</td>      <th>  BIC:               </th> <td>  -1458.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0002</td> <td>    0.022</td> <td>    0.011</td> <td> 0.991</td> <td>   -0.042     0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ListingPrice</th>         <td> 3.109e-06</td> <td> 1.11e-05</td> <td>    0.279</td> <td> 0.780</td> <td>-1.87e-05  2.49e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SellerFeedbackRating</th> <td>-1.935e-05</td> <td>    0.000</td> <td>   -0.082</td> <td> 0.935</td> <td>   -0.000     0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_BC</th>         <td>    0.2599</td> <td>    0.013</td> <td>   20.468</td> <td> 0.000</td> <td>    0.235     0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_PA</th>         <td>    0.1898</td> <td>    0.097</td> <td>    1.963</td> <td> 0.050</td> <td>    0.000     0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsFeaturedMerchant</th>   <td>    0.0503</td> <td>    0.007</td> <td>    7.129</td> <td> 0.000</td> <td>    0.036     0.064</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4356.316</td> <th>  Durbin-Watson:     </th> <td>   2.090</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>55953.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.640</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>16.286</td>  <th>  Cond. No.          </th> <td>1.16e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               IsWinner   R-squared:                       0.082\n",
       "Model:                            OLS   Adj. R-squared:                  0.081\n",
       "Method:                 Least Squares   F-statistic:                     104.1\n",
       "Date:                Tue, 18 Apr 2017   Prob (F-statistic):          1.40e-105\n",
       "Time:                        22:10:30   Log-Likelihood:                 755.21\n",
       "No. Observations:                5851   AIC:                            -1498.\n",
       "Df Residuals:                    5845   BIC:                            -1458.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0002      0.022      0.011      0.991        -0.042     0.043\n",
       "ListingPrice          3.109e-06   1.11e-05      0.279      0.780     -1.87e-05  2.49e-05\n",
       "SellerFeedbackRating -1.935e-05      0.000     -0.082      0.935        -0.000     0.000\n",
       "ShipsFrom_BC             0.2599      0.013     20.468      0.000         0.235     0.285\n",
       "ShipsFrom_PA             0.1898      0.097      1.963      0.050         0.000     0.379\n",
       "IsFeaturedMerchant       0.0503      0.007      7.129      0.000         0.036     0.064\n",
       "==============================================================================\n",
       "Omnibus:                     4356.316   Durbin-Watson:                   2.090\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            55953.292\n",
       "Skew:                           3.640   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.286   Cond. No.                     1.16e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.16e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Significance:\n",
    "\n",
    "#### Looking at Coefficients:\n",
    "\n",
    "1. From the coefficients we can see that ShipsFrom_BC, ShipsFrom_PA and Featured Merchant have the most affect on the likelyhood of an offer being a 'winner'. \n",
    "2. While Listing Price has a much lower coefficient in this model and Seller Feedback Rating has a negative. \n",
    "\n",
    "Reference for interpreting coefficients: https://github.com/justmarkham/DAT4/blob/master/notebooks/08_linear_regression.ipynb\n",
    "\n",
    "#### Looking at P-Values:\n",
    "\n",
    "1. By looking at the P-Values we can see that ShipsFrom_BC, ShipsFrom_PA and Featured Merchant are again the most statistically significant features. As they all have a P-Value below 0.5. \n",
    "\n",
    "2. The r-squared value is quite low indicating that I have underfitted the model. \n",
    "\n",
    "#### What next? \n",
    "\n",
    "With the above in mind, I am going to look at the features IsFeaturedMerchant, ShipsFrom_BC and ShipsFrom_PA as these are stastically significant both in terms of their coefficients and their P-Values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Retrain the model using only the subset of features found to be statistically significant. Evaluate the quailty of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols_2 = ['IsFeaturedMerchant', 'ShipsFrom_BC', 'ShipsFrom_PA']\n",
    "df_new = df[['IsWinner', 'IsFeaturedMerchant', 'ShipsFrom_BC', 'ShipsFrom_PA']]\n",
    "\n",
    "lm_2 = sm.ols(formula=\"IsWinner ~ IsFeaturedMerchant + ShipsFrom_BC + ShipsFrom_PA\", data=df_new).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#printing the predicted target feature value for next question before thresholding\n",
    "lm2_predictions = lm_2.predict(df_new[feature_cols_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Threshold at 0.5 and put in appropriate predicted class\n",
    "predicted_class = list()\n",
    "for i in lm2_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1               0\n",
       "1               0               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              1               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              0               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              1               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "5821            0               0\n",
       "5822            0               0\n",
       "5823            0               0\n",
       "5824            0               0\n",
       "5825            0               0\n",
       "5826            1               0\n",
       "5827            0               0\n",
       "5828            0               0\n",
       "5829            0               0\n",
       "5830            0               0\n",
       "5831            0               0\n",
       "5832            0               0\n",
       "5833            0               0\n",
       "5834            0               0\n",
       "5835            0               0\n",
       "5836            0               0\n",
       "5837            0               0\n",
       "5838            0               0\n",
       "5839            0               0\n",
       "5840            0               0\n",
       "5841            0               0\n",
       "5842            0               0\n",
       "5843            0               0\n",
       "5844            0               0\n",
       "5845            0               0\n",
       "5846            0               0\n",
       "5847            0               0\n",
       "5848            0               0\n",
       "5849            0               0\n",
       "5850            0               0\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lm2_predictions = lm_2.predict(df_new[feature_cols_2])\n",
    "df_true_vs_lm2_predicted = pd.DataFrame({'ActualClass': df_new.IsWinner, 'PredictedClass': predicted_class})\n",
    "df_true_vs_lm2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_lm2_predicted[\"ActualClass\"], df_true_vs_lm2_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_lm2_predicted[\"ActualClass\"], df_true_vs_lm2_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_lm2_predicted[\"ActualClass\"], df_true_vs_lm2_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.948043069561\n",
      "Confusion matrix: \n",
      " [[5547    0]\n",
      " [ 304    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5547\n",
      "          1       0.00      0.00      0.00       304\n",
      "\n",
      "avg / total       0.90      0.95      0.92      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Analysis: \n",
    "\n",
    "It's hard to tell what's happening here because we have gotten the exact same results even though I have only included the features that were shown to be statistically significant. It may be that we have to look at the appropriateness of using a linear regression model with this data set at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Threshold the predicted target feature value at 0.5 get the predicted class for each example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04939578,  0.04939578,  0.04939578, ...,  0.04939578,\n",
       "        0.04939578,  0.04939578])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both models produce the same results - I have done the thresholding above in order to evaluate the models using\n",
    "# Confusion matrix - see below for the predicted class before thresholding and 2.3 for the predicted class after thresholding\n",
    "lm2_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Predictive Modeling: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train a logistic regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.175317\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train a model using logistic regression & statsmodels\n",
    "# I had to cut out a feature here because I got a LinAlg Singular Matrix Error - from what I can gather online that means \n",
    "# that there is no solution to the model proposed - I cut the least significant feature - ShispFrom_PA\n",
    "feature_cols.remove(\"ShipsFrom_PA\")\n",
    "df_log = df[['IsWinner', 'ListingPrice', 'IsFeaturedMerchant', 'SellerFeedbackRating', 'ShipsFrom_BC']]\n",
    "logreg = sm.logit(formula=\"IsWinner ~ ListingPrice + IsFeaturedMerchant + SellerFeedbackRating + ShipsFrom_BC\", data=df_log).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(df_log[feature_cols])\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1               0\n",
       "1               0               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              1               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              0               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              1               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "5821            0               0\n",
       "5822            0               0\n",
       "5823            0               0\n",
       "5824            0               0\n",
       "5825            0               0\n",
       "5826            1               0\n",
       "5827            0               0\n",
       "5828            0               0\n",
       "5829            0               0\n",
       "5830            0               0\n",
       "5831            0               0\n",
       "5832            0               0\n",
       "5833            0               0\n",
       "5834            0               0\n",
       "5835            0               0\n",
       "5836            0               0\n",
       "5837            0               0\n",
       "5838            0               0\n",
       "5839            0               0\n",
       "5840            0               0\n",
       "5841            0               0\n",
       "5842            0               0\n",
       "5843            0               0\n",
       "5844            0               0\n",
       "5845            0               0\n",
       "5846            0               0\n",
       "5847            0               0\n",
       "5848            0               0\n",
       "5849            0               0\n",
       "5850            0               0\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with accuracy and confusion matrix\n",
    "df_true_vs_logreg_pred = pd.DataFrame({'ActualClass': df_log.IsWinner, 'PredictedClass': predicted_class})\n",
    "df_true_vs_logreg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.948043069561\n",
      "Confusion matrix: \n",
      " [[5547    0]\n",
      " [ 304    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5547\n",
      "          1       0.00      0.00      0.00       304\n",
      "\n",
      "avg / total       0.90      0.95      0.92      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Analysis: \n",
    "\n",
    "Again, the results are the same as in 2.1 - we are predicting all negatives. We have failed to predict any instances in the positive class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g. interpret the model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept              -25.503662\n",
      "ListingPrice             0.000066\n",
      "IsFeaturedMerchant      23.310172\n",
      "SellerFeedbackRating    -0.008162\n",
      "ShipsFrom_BC             2.156174\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(logreg.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 5851\n",
      "Model:                          Logit   Df Residuals:                     5846\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.1416\n",
      "Time:                        22:10:32   Log-Likelihood:                -1025.8\n",
      "converged:                      False   LL-Null:                       -1195.0\n",
      "                                        LLR p-value:                 5.520e-72\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              -25.5037   1.35e+04     -0.002      0.998     -2.65e+04  2.64e+04\n",
      "ListingPrice          6.638e-05      0.000      0.259      0.795        -0.000     0.001\n",
      "IsFeaturedMerchant      23.3102   1.35e+04      0.002      0.999     -2.64e+04  2.65e+04\n",
      "SellerFeedbackRating    -0.0082      0.009     -0.907      0.364        -0.026     0.009\n",
      "ShipsFrom_BC             2.1562      0.144     14.986      0.000         1.874     2.438\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.22 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "print(logreg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance \n",
    "\n",
    "### Looking at Coefficients\n",
    "\n",
    "1. Keep in mind we have reduced by one feature because of the Singular Matrix error. The most significant feature by far is Featured Merchant followed by ShipsFrom_BC. We can see that Featured Merchant has 10 times an impact on the target outcome than ShipsFrom_Bc. \n",
    "\n",
    "### Looking at PValues\n",
    "\n",
    "1. Looking at the pvalues we can see that Ships From BC and Seller Feedback Rating are the lowest values - here we see a divergence from the results seen above with the coefficients. \n",
    "\n",
    "### What Next?\n",
    "\n",
    "Although Featured Merchant does not have a 'good' P-Value I am going to include it going further because of the scale of its coefficient. In addition I am also going to include ShipsFrom_BC as that has the best P-Value and see how this simple model works moving forward. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Retrain the model using only the subset of features found to be statistically significant. Evaluate the quality of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maintain the prepared data frame for use in part 3 and part 4\n",
    "df_newlog = df[['IsWinner', 'IsFeaturedMerchant', 'ShipsFrom_BC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.175383\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_cols_2 = ['IsFeaturedMerchant', 'ShipsFrom_BC']\n",
    "\n",
    "logreg2 = sm.logit(formula=\"IsWinner ~ IsFeaturedMerchant + ShipsFrom_BC\", data=df_newlog).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = logreg2.predict(df_newlog[feature_cols_2])\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1               0\n",
       "1               0               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              1               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              0               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              1               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "5821            0               0\n",
       "5822            0               0\n",
       "5823            0               0\n",
       "5824            0               0\n",
       "5825            0               0\n",
       "5826            1               0\n",
       "5827            0               0\n",
       "5828            0               0\n",
       "5829            0               0\n",
       "5830            0               0\n",
       "5831            0               0\n",
       "5832            0               0\n",
       "5833            0               0\n",
       "5834            0               0\n",
       "5835            0               0\n",
       "5836            0               0\n",
       "5837            0               0\n",
       "5838            0               0\n",
       "5839            0               0\n",
       "5840            0               0\n",
       "5841            0               0\n",
       "5842            0               0\n",
       "5843            0               0\n",
       "5844            0               0\n",
       "5845            0               0\n",
       "5846            0               0\n",
       "5847            0               0\n",
       "5848            0               0\n",
       "5849            0               0\n",
       "5850            0               0\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with accuracy and confusion matrix\n",
    "df_true_vs_logreg_pred = pd.DataFrame({'ActualClass': df_newlog.IsWinner, 'PredictedClass': predicted_class})\n",
    "df_true_vs_logreg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.948043069561\n",
      "Confusion matrix: \n",
      " [[5547    0]\n",
      " [ 304    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5547\n",
      "          1       0.00      0.00      0.00       304\n",
      "\n",
      "avg / total       0.90      0.95      0.92      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Analysis: \n",
    "\n",
    "The models here may be underfitted too much because they are only producing negatives and not successfully producing any postive cases. They are too 'simple' and perhaps need to better fit the data given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04937983,  0.04937983,  0.04937983, ...,  0.04937983,\n",
       "        0.04937983,  0.04937983])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I had to threshold the data above to evaluate the model - see below for detailed predictions and see 3.3 for predicted class\n",
    "# After thresholding\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Predictive Modeling: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Train a random forest model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reference: https://www.youtube.com/watch?v=0GrciaGYzV0&list=PLx1nh9sMznmKoUjw6uHR2enxCrenhn5zD&index=4\n",
    "# Going back to our original set of selected features for Random Forest - Hopefully we won't get Singular Matrix Error\n",
    "feature_cols = ['IsFeaturedMerchant', 'ListingPrice', 'SellerFeedbackRating', 'ShipsFrom_BC']\n",
    "X = df[feature_cols]\n",
    "y = df.IsWinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm = RandomForestRegressor(oob_score=True)\n",
    "rfm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.082792643917920405"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out of bag score - only available after the model has been trained (all methods with trailing underscore are only available\n",
    "#after the model has been trained) This produces the r squared value\n",
    "rfm.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Stat:  0.779512159252\n"
     ]
    }
   ],
   "source": [
    "#we can use this to calculate roc/auc\n",
    "y_oob = rfm.oob_prediction_\n",
    "print(\"C-Stat: \", roc_auc_score(y, y_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_predictions = rfm.predict(X)\n",
    "predicted_class = list()\n",
    "for i in rfc_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1               1\n",
       "1               0               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              1               1\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              0               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              1               1\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "5821            0               0\n",
       "5822            0               0\n",
       "5823            0               0\n",
       "5824            0               0\n",
       "5825            0               0\n",
       "5826            1               0\n",
       "5827            0               0\n",
       "5828            0               0\n",
       "5829            0               0\n",
       "5830            0               0\n",
       "5831            0               0\n",
       "5832            0               0\n",
       "5833            0               0\n",
       "5834            0               0\n",
       "5835            0               0\n",
       "5836            0               0\n",
       "5837            0               0\n",
       "5838            0               0\n",
       "5839            0               0\n",
       "5840            0               0\n",
       "5841            0               0\n",
       "5842            0               0\n",
       "5843            0               0\n",
       "5844            0               0\n",
       "5845            0               0\n",
       "5846            0               0\n",
       "5847            0               0\n",
       "5848            0               0\n",
       "5849            0               0\n",
       "5850            0               0\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_vs_rfc_predicted = pd.DataFrame({'ActualClass': y, 'PredictedClass': predicted_class})\n",
    "df_true_vs_rfc_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.988378055033\n",
      "Confusion matrix: \n",
      " [[5517   30]\n",
      " [  38  266]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      5547\n",
      "          1       0.90      0.88      0.89       304\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Analysis:\n",
    "\n",
    "1. Finally we can see some good results here with the Random Forest Model. The number of false positives is only 27 and the number of false negatives is only 36. The accuracy of the model is 99% which is excellent. This is definitely a much more effective model than either of the linear regression or logistic regression models that I tried. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Print the features ranked by random forest importance. Discuss your findings and choose a subset of features you find promising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01298132,  0.86087813,  0.05273397,  0.07340657])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFkCAYAAADBklkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF8dJREFUeJzt3XucnXV94PFPIIEYo9SIEDAiVMqXi4Ci3GGJCWBFS9DW\nFoqr3G+i2KJubFSoNV1oDa0uFQqsxV2kKKz1ZaiieYm44WZQl3L/IreVsMQoIBgFAsnsH88zejqd\nmUySyZw5+X7er9e8Zs5znsvvPI58zu95TpIJfX19SJKkGjbp9gAkSdLYMfySJBVi+CVJKsTwS5JU\niOGXJKmQid0egNZPRGwO7A08Dqzq8nAkSd23KbANcFtmPj/wScPf+/YGFnd7EJKkcedg4MaBCw1/\n73sc4Etf+hLTp0/v9lgkSV22bNkyjj32WGj7MJDh732rAKZPn86MGTO6PRZJ0vgx6O1fP9wnSVIh\nhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JUiOGXJKkQwy9JUiGGX5KkQgy/JEmFGH5Jkgox\n/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIRO7PQCNjpPmL2LSlGndHoYkaT0sXDBngx/DGb8kSYUY\nfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTw\nS5JUiOGXJKkQwy9JUiGGX5KkQiZ2ewAbSkTMBE7LzKM7ll0FvDczVw6y/jTg9zPzyoiYC1yfmUvW\n8pgrgZuBPmAScC9wema+2LHOdOCTmXnGOrwsSZLWy0Yb/sF0vgkYxB7AkcCVmXneOh7iycyc2f8g\nIr4MHAF8vWMMywCjL0nqilLhj4hHgJ1pYvxfgBeA/wccDcwD9oyIU4ADgKuA6e26U4DXAedn5uUR\nsQ/wD8AvgeXAc5l53IBjTQKmAisi4tx2n1OBE4F/ysz9IuIdwDnABOBHwGnAwcB8YBXwIHBqZr4w\n+mdDklRR1Xv8xwB/m5kHAdcCL6eJ7fWZecmAdbfIzHfQXA2Y2y67GDguM2fRxLnftIi4ISK+C3wL\nuCEzr2+fuzczDwCeBYiIicCFwNsz883AA8BrgEuBd2XmIcBjwHGj+LolScWVmvF3+HPgYxHxAZr7\n8F8bZt3b2++PApPbn7fNzLvbnxfTXDGAAZf6B8gBj7cEnsrM5QCZ+TcRsRWwDfCViAB4CbBoRK9I\nkqQRqDrjPwU4t51VTwDeCaxm8PPRN8iyRyNi1/bn/UZ4zNUDHi8Hfqf9UCER8Tlge2ApMKd9AzEf\nuB5JkkbJxj7jPzwiftDxeLP2+xLg2oj4JbCC5nL/ZGD3iPjQCPZ7BvCFiFgBrKS5JL9WMnN1RJwB\n/GtErAL+D3AbcFa7bBPgGeC9a7tvSZKGstGGPzNvAKYN8fTC9mugXYbZ33M0M3KAfYA/yMyfRcSn\naeJPZk4fYttzO35+hPYqQWZ+E/jmgNW/3X5JkjTqNtrwb2A/Bb7dzvifBt7X5fFIkjQihn8dZOY1\nwDXdHockSWur6of7JEkqyfBLklSI4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmSCjH8kiQVYvglSSrE\n8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhfjP8m4kLpt3GDNmzOj2MCRJ45wzfkmSCjH8kiQVYvgl\nSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JUiOGXJKkQwy9J\nUiGGX5KkQgy/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmS\nCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JU\niOGXJKkQwy9JUiGGX5KkQgy/JEmFTOz2ADQ6Tpq/iElTpo35cRcumDPmx5QkrTtn/JIkFWL4JUkq\nxPBLklSI4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIh\nhl+SpEIMvyRJhRh+SZIKmdjtAQwnIuYChwKTgNXAh4EFwGmZeV/Hem8AjszMT63FvrcH7gB+1LH4\n+rXZx9oacMwJwEuBj2Xmovb5o4Cz2udeAvxtZl6zocYjSapn3IY/InYFjgQOzMy+Nu5fBJ4auG5m\n3g7cvg6HuSczZ67XQNfjmBGxE/BV4PURcQDwZ8DbM3NFRLwSuDUi7snMe8Z4jJKkjdS4DT/wNLAd\ncEJEXJeZt0fEPsC3gHMiYmuaGfMx7XqnZebREfEQ8H3gdcBdwEnA/jRXCl4Afg380VAHjYiZwPnA\nSuASYBnwaeA54AngBOANwMeA54HXABcDs4A9gc9m5kUjfI2vAJa3P58M/H1mrgDIzCfa1/uLEe5L\nkqQ1Grfhz8zHIuJI4Eya0P8amNc+/a+ZeUVEnEsT8SUdm84ADs/MByLiK8BRNOH/CvD3NFcRXtGu\nu2tE3NCx7bHt98mZuW9ETAAeAg5qx3MW8HHg2vY4bwDeBFxN80bj1cC/AMOFv/+YE4E3Ah9ol2/b\nHqvzHPyHqxuSJK2PcfvhvojYEXgmM0/IzO2A99DMrKcBP2xXWwZMGbDpTzLzgfbnm4EA/pomrN+h\neaPwQvv8PZk5s+PrsXZ5tt+3bMfQv/x/A7u1P9+VmS/QzMgfzMyVNLchJq/hpfUf8yCaNwvzI+K1\nwP+luXrQeQ4ObM+DJEmjYtyGH9gDuDAiNmsf308T2VVA3zDbvToiprc/HwjcTfOm4fLMfEv7+JQ1\nHHt1+/3nwMsjYpv28SHtOFjDGEbqSeBZmtn/PwEfiYiXAkTEVu2ygW9sJElaZ+P5Uv9XI2IX4LaI\nWEHzJuUjwIfWsOnzNG8YXgPcCiwE9gEui4hf0UR9TeHvH0NfRJwMfDUiVtPM6I8DXr8OL6lf/6X+\n1TSfUbg0Mx8EHoyIS4BFEfECzaf6P5aZd6zHsSRJ+ncm9PWNxsR1/IiIZZk5fc1rbhzaPyL48A6z\n5jJpyrQxP/7CBXPG/JiSpKEtXbqU2bNnA+yQmY8MfH7czvh7WUR8kuZT/gMdn5kPj/V4JEnqt9GF\nfzzM9tu/BGiD/UVAkiStq/H84T5JkjTKDL8kSYUYfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMv\nSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKmSj+9f5qrps3mHMmDGj28OQJI1zzvglSSrE8EuS\nVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JUiOGXJKkQwy9JUiGGX5Kk\nQgy/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmSCjH8kiQV\nYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JUiOGXJKkQ\nwy9JUiGGX5KkQgy/JEmFGH5Jkgox/JIkFTKx2wPQ6Dhp/iImTZk2qvtcuGDOqO5PktR9zvglSSrE\n8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTwS5JUiOGXJKkQwy9JUiGG\nX5KkQgy/JEmFGH5Jkgox/JIkFWL4JUkqZOJIVoqIucChwCRgNfDhzPzhIOvNBE7LzKMjYllmTh/h\n/i8H9gKe7Fj83sz8yUi2H2R/pwHTgcuBqzJzv3XZT7uv//A6IuIR4Cc052JTYCpwcmb+YJj9nJmZ\nF0bE7wPbZeYl6zomSZLW1RrDHxG7AkcCB2ZmX0S8AfgisOcoj+WjmXndKO9zQzo8M58DiIi3AucC\n7xhm/Y8DF/bYa5QkbWRGMuN/GtgOOCEirsvM2yNin4jYHfgcMAF4AjhhsI2HWO+NwPnASmDIme9g\n22bm0xHxX4GDaWbbF2Tm1RFxEPBZ4CngReDWdjevioivA1sD12bmX0XE64EL2u23BE7PzJsj4kTg\n9Hb51zPznI6x/DWwBXDmIEN9bXtcIuKPgPfTXB3pA94JnApMi4jPA0uAnYGLgX8GHgVeByzJzNMj\nYkvgSmBzIIFZmbnjUOdIkqS1scZ7/Jn5GO2MH7glIu6jmdleCrw/M2cC3wA+OsQuhlpvcmYenJn/\ns338NxFxQ/s1b6htI+JtwA6ZeRDwFmBeRPwOcBFwTGYeCjzccfypwH8GDgDeFhF7ArsBZ2fmbJo3\nIMdHxFbAXJo3FHsBm0fEVICI+AwwMTPfn5l97X6/HRFLImIpsA/w4Xb5TsDb2/HdA7w1M+cDT2bm\nGQPOzU7Aie32R0TEdGAe8LXMPAS4mhHejpEkaSRGcql/R+CZzDyhffxm4JvAZODzEQHN7PbHQ+xi\nlyHWywHrDXapf7BtdwfeFBE3tOtMArYHts7M+9tlNwH9s+R/y8yn27EvoYntY8AnIuJZ4GXAM8Dv\nAndl5rPtdnPbbbYG9gAeGDC2wzPzufZKwA7A8nb5cuCLEbGCZmZ/yxDnBeCBzPxle5zHac7pLjS3\nUgAWD7OtJElrbSSf6t8DuDAiNmsf3w/8giaE721n4x8Frh1i+xxivdUjOPZg294HfLddNgv4CvAg\n8FhE7NJut3fHPnaJiKkRMRHYF7ib5vbBOZn5PuBOmlsJDwI7R8TmABFxTUS8Gvgp8FZgt/aDeQN9\nHNgWOCMitgD+EjgaOAl4tt03Hd879Q2y7C5g//bndf5QoiRJgxnJpf6v0sw8b4uIm4BvAR+hCdv/\niIgbgfOAO4bYxekjXG+k2y4EVkTEYuCHQF87az61Xfc7NPfc+z0JfBm4GbgmM+8BrgCubvexE7Bt\nZv6M5rL/9yLiFuBH7W0O2sv7J9K8AXrlgPOzuj0XH6e5rXATzSx/MU34t21XvScirhjBaz4PODIi\nvgucDLwwslMlSdKaTejrG2zSqW6JiCOAn2XmbRFxKPAXmTlrmPW3Bx7eYdZcJk2ZNqpjWbhgzqju\nT5K04S1dupTZs2dD83m4RwY+7wfHxp+HgS9ExIs0f7rgg10ejyRpI2L4x5nMvJff3uOXJGlU+Vf2\nSpJUiOGXJKkQwy9JUiGGX5KkQgy/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZf\nkqRCDL8kSYX4r/NtJC6bdxgzZszo9jAkSeOcM35Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lS\nIYZfkqRCDL8kSYUYfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIK\nMfySJBVi+CVJKsTwS5JUiOGXJKkQwy9JUiGGX5KkQgy/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI\n4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIM\nvyRJhUzs9gA0Ok6av4hJU6b95vHCBXO6OBpJ0njljF+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKsTw\nS5JUiOGXJKkQwy9JUiGGX5KkQgy/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIRNH\nYycRsT1wVWbuN8hzxwGfAh7qWHxBZn59LfY/GXhPZl62nkPt3OdVwMXtw+8Cx2TmVR3P3wH8KDOP\nW8f9b88Q52Qt9jHqr1uSVNuohH8ErszMueux/XTgJGBDBfA+4GjgKoCI2B146QY61trY0K9bklTM\nqIY/Is4A3gesBm7LzA8Os+4WwH8HXtku+mBm3hkRZwLvognvz4F3AvOAXSPikzS3J5Zl5sURsTNw\ncWbOjIi7gPuBlcCpQ+z7/TQhfRzYqmM4/9YMKbbIzKeB9wBfArZrx/pu4M+BVcCNmTk3Is4FDgCm\nAicCfwgcRXNOLwK+BbwqIr4GbAPckZknR8TrgQuATYEtgdMz8+aI+DFwExDAT9v9/eZ1Z+anRvK/\ngSRJwxnte/zHA2dm5v7AvRHR/8biTyPihvbr6nbZXwDfycy3AKcAF0XEJjSxPjQz96WJ6N7AfOCe\nNcRvKvBXmXn0EPveGjgL2A+YA2w2YPv/BbwrIiYA+wA3A0TENOAvgdmZeRDw6og4rN3m3sw8AJgM\nvA3Yt912J2AC8PL2nOwPzI6IrYDdgLMzczZwfvs8wO8Cn2jP3avW4nVLkjRio32p/3jgwxGxA3AL\nTfxg8Ev9uwOzIuJP2sfTMnN1RKwE/jkiVgAzgEnDHG/CgMc51L6B1wF3Z+bzABGxZMC2V9LM1B8C\nFncs35EmxN+ICICXtfvqPF4ASzJzFc1VgbPbe/wPZeZT7fGWA1OAx4BPRMSz7b6eaffx88x8tP35\nUZo3E5IkjarRnvGfDJyWmYcAb6S5FD6U+4C/y8yZwB8DV0TEHsBRmfknwAfa8U2guXXQP9bnaC6d\nA+w1YJ+rh9o38GNgt4h4SURs2o7vNzLzIZrbCx9s1+/3ME2ID2v399+AWwc53l4RsUlETIqIRcDm\nQN8gr/tzwDmZ+T7gTn775mWwdTtftyRJ6220o3InsDgirgeWA98fZt35wB9HxA3AdcBdwAPAryLi\nJmARzb34bdt9bRYR5wNfBo5otxsY/iH3nZk/A86juYT/TeBXg2z3ZeA1mXl//4J2uwuA70XE92ku\n6d/fuVFm3t4e5ybgRprPBzw/xNiuAK6OiMU0twS2HWI9BrxuSZLW24S+vsEmmuoV7S2Fh3eYNZdJ\nU6b9ZvnCBXO6NiZJUvcsXbqU2bNnA+yQmY8MfN7LyJIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZf\nkqRCDL8kSYUYfkmSCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhUzs9gA0Oi6b\ndxgzZszo9jAkSeOcM35Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZfkqRCDL8kSYUYfkmS\nCjH8kiQVYvglSSrE8EuSVIjhlySpEMMvSVIhhl+SpEIMvyRJhRh+SZIKMfySJBVi+CVJKmRitweg\n9bYpwLJly7o9DknSONDRg00He97w975tAI499thuj0OSNL5sAzw4cKHh7323AQcDjwOrujwWSVL3\nbUoT/dsGe3JCX1/f2A5HkiR1jR/ukySpEMMvSVIhhl+SpEIMvyRJhfip/h4REZsAnwf2BJ4HTsrM\nBzqe/wPgk8CLwBcy89KuDLTHjOC8HgN8iOa83gmckZmruzHWXrOmc9ux3iXAk5k5d4yH2JNG8Du7\nN3ABMAFYBrwnM5/rxlh7zQjO7bHA2TR/guoLmXlRVwa6npzx946jgMmZuT8wF1jQ/0RETAL+Djgc\nOAQ4JSK27sooe89w5/UlwKeBt2TmgcAWwDu6MsreNOS57RcRpwK7j/XAetxwv7MTgEuB4zPzIOA6\n4LVdGWVvWtPv7GeAQ4EDgbMj4hVjPL5RYfh7R///icnMW4E3dzy3C/BAZj6VmSuBG4H/NPZD7EnD\nndfngQMy89ft44mAM6eRG+7cEhEHAPsC/zj2Q+tpw53XnYAngD+LiO8B0zIzx36IPWvY31ngDpoJ\nwGSaKyo9+efhDX/veDnwdMfjVRExcYjnfknzy6k1G/K8ZubqzPwpQER8AJgKLBr7IfasIc9tRGwD\nnAOc2Y2B9bjh/luwJXAAcCHNzHR2RMwa4/H1suHOLcBdwA+Bu4FrM/MXYzm40WL4e8czwMs6Hm+S\nmS8O8dzLgJ78heyC4c4rEbFJRHwGOAz4w8zsyXf4XTLcuX03TaS+QXNJ9U8j4rixHV7PGu68PkFz\n9e/ezHyBZvY6cNaqoQ15biNiD+DtwA7A9sBWEfHuMR/hKDD8veMm4AiAiNiP5oNm/e4Ffi8ipkXE\nZjSX+W8Z+yH2pOHOKzSXoScDR3Vc8tfIDHluM/NzmfmmzJwJnAdcmZmXd2OQPWi439mHgKkRsWP7\n+GCa2alGZrhz+zTwLPBsZq4ClgM9eY/fv7K3R3R82nQPmntLxwN7AVMz85KOT/VvQvNp03/o2mB7\nyHDnFfhB+7WY397L+2xm/ksXhtpz1vQ727HeccDOfqp/ZEbw34JZNG+mJgA3Z+ZZXRtsjxnBuT0N\nOAFYSfOP35zcfq6qpxh+SZIK8VK/JEmFGH5Jkgox/JIkFWL4JUkqxPBLklSI4ZckqRDDL0lSIYZf\nkqRC/j9y5U0Vvee9mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146db9f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.Series(rfm.feature_importances_, index=X.columns)\n",
    "feature_importances.sort_values(inplace = True)\n",
    "feature_importances.plot(kind=\"barh\", figsize=(7, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Feature Importance:\n",
    "\n",
    "Looking at the above graph we can clearly see that Listing Price has the highest ranking in terms of importance.\n",
    "\n",
    "Because there is such a massive difference in feature importance between Listing Price and the next feature I am going to try a very simple model with just listing price to see how that works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Retrain the model using only the subset of features found to be promising. Evaluate the quality of the model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IsWinner', 'IsFeaturedMerchant', 'ListingPrice',\n",
       "       'SellerFeedbackRating', 'ShipsFrom_BC', 'ShipsFrom_PA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf = df[['IsWinner', 'ListingPrice']]\n",
    "feature_cols = [\"ListingPrice\"]\n",
    "X = df_rf[feature_cols]\n",
    "rfm2 = RandomForestRegressor(oob_score=True)\n",
    "rfm2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00283005356181254"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Stat:  0.739607054074\n"
     ]
    }
   ],
   "source": [
    "y_oob = rfm2.oob_prediction_\n",
    "print(\"C-Stat: \", roc_auc_score(y, y_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_predictions = rfm2.predict(X)\n",
    "predicted_class = list()\n",
    "for i in rfc_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1               1\n",
       "1               0               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              1               1\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              0               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              1               1\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "5821            0               0\n",
       "5822            0               0\n",
       "5823            0               0\n",
       "5824            0               0\n",
       "5825            0               0\n",
       "5826            1               0\n",
       "5827            0               0\n",
       "5828            0               0\n",
       "5829            0               0\n",
       "5830            0               0\n",
       "5831            0               0\n",
       "5832            0               0\n",
       "5833            0               0\n",
       "5834            0               0\n",
       "5835            0               0\n",
       "5836            0               0\n",
       "5837            0               0\n",
       "5838            0               0\n",
       "5839            0               0\n",
       "5840            0               0\n",
       "5841            0               0\n",
       "5842            0               0\n",
       "5843            0               0\n",
       "5844            0               0\n",
       "5845            0               0\n",
       "5846            0               0\n",
       "5847            0               0\n",
       "5848            0               0\n",
       "5849            0               0\n",
       "5850            0               0\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_vs_rfc_predicted = pd.DataFrame({'ActualClass': y, 'PredictedClass': result})\n",
    "df_true_vs_rfc_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_rfc_predicted[\"ActualClass\"], df_true_vs_rfc_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.983421637327\n",
      "Confusion matrix: \n",
      " [[5506   41]\n",
      " [  56  248]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      5547\n",
      "          1       0.86      0.82      0.84       304\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Analysis: \n",
    "\n",
    "1. This model is slightly worse than the previous one - it is only 98% accurate and has a slightly higher number of false positives and false negatives. Although it is still much more effective than either of the linear regression or logistic regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first Random Forest Model was more effective so we will use this one to print the predicted target feature\n",
    "feature_cols = ['IsFeaturedMerchant', 'ListingPrice', 'SellerFeedbackRating', 'ShipsFrom_BC']\n",
    "X = df[feature_cols]\n",
    "y = df.IsWinner\n",
    "rfm = RandomForestRegressor(oob_score=True)\n",
    "rfm.fit(X, y)\n",
    "rfc_predictions = rfm.predict(X)\n",
    "rfc_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>1</td>\n",
       "      <td>0.578333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>0</td>\n",
       "      <td>0.578333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               1        1.000000\n",
       "1               0        0.000000\n",
       "2               0        0.000000\n",
       "3               0        0.000000\n",
       "4               0        0.000000\n",
       "5               0        0.000000\n",
       "6               0        0.000000\n",
       "7               0        0.000000\n",
       "8               0        0.000000\n",
       "9               0        0.300000\n",
       "10              0        0.000000\n",
       "11              0        0.000000\n",
       "12              0        0.000000\n",
       "13              1        1.000000\n",
       "14              0        0.000000\n",
       "15              0        0.000000\n",
       "16              0        0.000000\n",
       "17              0        0.000000\n",
       "18              0        0.000000\n",
       "19              0        0.000000\n",
       "20              0        0.000000\n",
       "21              0        0.000000\n",
       "22              0        0.000000\n",
       "23              0        0.000000\n",
       "24              0        0.000000\n",
       "25              1        0.800000\n",
       "26              0        0.000000\n",
       "27              0        0.000000\n",
       "28              0        0.000000\n",
       "29              0        0.000000\n",
       "...           ...             ...\n",
       "5821            0        0.000000\n",
       "5822            0        0.000000\n",
       "5823            0        0.000000\n",
       "5824            0        0.000000\n",
       "5825            0        0.000000\n",
       "5826            1        0.578333\n",
       "5827            0        0.000000\n",
       "5828            0        0.000000\n",
       "5829            0        0.000000\n",
       "5830            0        0.000000\n",
       "5831            0        0.000000\n",
       "5832            0        0.000000\n",
       "5833            0        0.000000\n",
       "5834            0        0.000000\n",
       "5835            0        0.000000\n",
       "5836            0        0.000000\n",
       "5837            0        0.000000\n",
       "5838            0        0.000000\n",
       "5839            0        0.578333\n",
       "5840            0        0.000000\n",
       "5841            0        0.000000\n",
       "5842            0        0.000000\n",
       "5843            0        0.000000\n",
       "5844            0        0.000000\n",
       "5845            0        0.000000\n",
       "5846            0        0.000000\n",
       "5847            0        0.000000\n",
       "5848            0        0.000000\n",
       "5849            0        0.000000\n",
       "5850            0        0.000000\n",
       "\n",
       "[5851 rows x 2 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slightly nicer display of the predictions\n",
    "df_true_vs_rfc2_predicted = pd.DataFrame({'ActualClass': y, 'PredictedClass': rfc_predictions})\n",
    "df_true_vs_rfc2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Evaluating Predictive Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Split the dataset into 70% training and remaining 30% test. Train all models from the previous exercises using the new training set and evaluate their quality on the new test set. Print classification evaluation metrics for all models on the test set (e.g., Accuracy, Confusion matrix, Precision, Recall, F1). Discuss how does evaluation on the test set compare to evaluation using the full data for training and also for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data into Training and Test Sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = ['IsFeaturedMerchant', 'ListingPrice', 'SellerFeedbackRating', 'ShipsFrom_BC', 'ShipsFrom_PA']\n",
    "X = df[feature_cols]\n",
    "X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#print(\"Training data:\\n\", pd.concat([X_train, y_train], axis=1))\n",
    "#print(\"\\nTest data:\\n\", pd.concat([X_test, y_test], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the model on the training set\n",
    "df_linear = pd.concat([X_train, y_train], axis = 1)\n",
    "lm = sm.ols(formula = \"IsWinner ~ IsFeaturedMerchant + ListingPrice + SellerFeedbackRating + ShipsFrom_BC + ShipsFrom_PA\", data=df_linear).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>IsWinner</td>     <th>  R-squared:         </th> <td>   0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   86.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Apr 2017</td> <th>  Prob (F-statistic):</th> <td>2.71e-86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:10:36</td>     <th>  Log-Likelihood:    </th> <td>  529.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4095</td>      <th>  AIC:               </th> <td>  -1047.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4089</td>      <th>  BIC:               </th> <td>  -1009.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.0050</td> <td>    0.026</td> <td>    0.197</td> <td> 0.844</td> <td>   -0.045     0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsFeaturedMerchant</th>   <td>    0.0497</td> <td>    0.008</td> <td>    5.904</td> <td> 0.000</td> <td>    0.033     0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ListingPrice</th>         <td>-9.272e-07</td> <td> 1.34e-05</td> <td>   -0.069</td> <td> 0.945</td> <td>-2.72e-05  2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SellerFeedbackRating</th> <td>-5.947e-05</td> <td>    0.000</td> <td>   -0.212</td> <td> 0.832</td> <td>   -0.001     0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_BC</th>         <td>    0.2862</td> <td>    0.015</td> <td>   18.911</td> <td> 0.000</td> <td>    0.257     0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_PA</th>         <td>   -0.0040</td> <td>    0.125</td> <td>   -0.032</td> <td> 0.974</td> <td>   -0.248     0.240</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3005.347</td> <th>  Durbin-Watson:     </th> <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>37697.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.557</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>16.051</td>  <th>  Cond. No.          </th> <td>1.24e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               IsWinner   R-squared:                       0.095\n",
       "Model:                            OLS   Adj. R-squared:                  0.094\n",
       "Method:                 Least Squares   F-statistic:                     86.10\n",
       "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           2.71e-86\n",
       "Time:                        22:10:36   Log-Likelihood:                 529.60\n",
       "No. Observations:                4095   AIC:                            -1047.\n",
       "Df Residuals:                    4089   BIC:                            -1009.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.0050      0.026      0.197      0.844        -0.045     0.055\n",
       "IsFeaturedMerchant       0.0497      0.008      5.904      0.000         0.033     0.066\n",
       "ListingPrice         -9.272e-07   1.34e-05     -0.069      0.945     -2.72e-05  2.53e-05\n",
       "SellerFeedbackRating -5.947e-05      0.000     -0.212      0.832        -0.001     0.000\n",
       "ShipsFrom_BC             0.2862      0.015     18.911      0.000         0.257     0.316\n",
       "ShipsFrom_PA            -0.0040      0.125     -0.032      0.974        -0.248     0.240\n",
       "==============================================================================\n",
       "Omnibus:                     3005.347   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37697.015\n",
       "Skew:                           3.557   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.051   Cond. No.                     1.24e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.24e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_predictions = lm.predict(X_test)\n",
    "predicted_class = list()\n",
    "for i in lm_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate the quality of the model on the test set\n",
    "df_true_vs_lm_predicted = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949886104784\n",
      "Confusion matrix: \n",
      " [[1668    0]\n",
      " [  88    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      1668\n",
      "          1       0.00      0.00      0.00        88\n",
      "\n",
      "avg / total       0.90      0.95      0.93      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train the model on the training set\n",
    "feature_cols_2 = ['IsFeaturedMerchant', 'ShipsFrom_BC', 'ShipsFrom_PA']\n",
    "df_linear = df_linear[['IsWinner', 'IsFeaturedMerchant', 'ShipsFrom_BC', 'ShipsFrom_PA']]\n",
    "lm_2 = sm.ols(formula = \"IsWinner ~ IsFeaturedMerchant + ShipsFrom_BC + ShipsFrom_PA\", data = df_linear).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>IsWinner</td>     <th>  R-squared:         </th> <td>   0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   143.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Apr 2017</td> <th>  Prob (F-statistic):</th> <td>1.93e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:10:37</td>     <th>  Log-Likelihood:    </th> <td>  529.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4095</td>      <th>  AIC:               </th> <td>  -1051.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4091</td>      <th>  BIC:               </th> <td>  -1026.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   -0.0003</td> <td>    0.007</td> <td>   -0.045</td> <td> 0.964</td> <td>   -0.014     0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsFeaturedMerchant</th> <td>    0.0492</td> <td>    0.008</td> <td>    6.100</td> <td> 0.000</td> <td>    0.033     0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_BC</th>       <td>    0.2863</td> <td>    0.015</td> <td>   18.937</td> <td> 0.000</td> <td>    0.257     0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShipsFrom_PA</th>       <td>    0.0003</td> <td>    0.123</td> <td>    0.003</td> <td> 0.998</td> <td>   -0.241     0.241</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3005.453</td> <th>  Durbin-Watson:     </th> <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>37701.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.557</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>16.052</td>  <th>  Cond. No.          </th> <td>    47.9</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               IsWinner   R-squared:                       0.095\n",
       "Model:                            OLS   Adj. R-squared:                  0.095\n",
       "Method:                 Least Squares   F-statistic:                     143.6\n",
       "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           1.93e-88\n",
       "Time:                        22:10:37   Log-Likelihood:                 529.57\n",
       "No. Observations:                4095   AIC:                            -1051.\n",
       "Df Residuals:                    4091   BIC:                            -1026.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             -0.0003      0.007     -0.045      0.964        -0.014     0.014\n",
       "IsFeaturedMerchant     0.0492      0.008      6.100      0.000         0.033     0.065\n",
       "ShipsFrom_BC           0.2863      0.015     18.937      0.000         0.257     0.316\n",
       "ShipsFrom_PA           0.0003      0.123      0.003      0.998        -0.241     0.241\n",
       "==============================================================================\n",
       "Omnibus:                     3005.453   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37701.423\n",
       "Skew:                           3.557   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.052   Cond. No.                         47.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate the quality of the model on the test set\n",
    "lm2_predictions = lm_2.predict(X_test[feature_cols])\n",
    "predicted_class = list()\n",
    "for i in lm2_predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_lm_predicted = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_lm_predicted[\"ActualClass\"], df_true_vs_lm_predicted[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949886104784\n",
      "Confusion matrix: \n",
      " [[1668    0]\n",
      " [  88    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      1668\n",
      "          1       0.00      0.00      0.00        88\n",
      "\n",
      "avg / total       0.90      0.95      0.93      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.175317\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Train the model on the training set\n",
    "feature_cols = ['IsFeaturedMerchant', 'ListingPrice', 'SellerFeedbackRating', 'ShipsFrom_BC']\n",
    "logreg = sm.logit(formula=\"IsWinner ~ IsFeaturedMerchant + ListingPrice + SellerFeedbackRating + ShipsFrom_BC\", data=df_log).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 5851\n",
      "Model:                          Logit   Df Residuals:                     5846\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.1416\n",
      "Time:                        22:10:37   Log-Likelihood:                -1025.8\n",
      "converged:                      False   LL-Null:                       -1195.0\n",
      "                                        LLR p-value:                 5.520e-72\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              -25.5037   1.35e+04     -0.002      0.998     -2.65e+04  2.64e+04\n",
      "IsFeaturedMerchant      23.3102   1.35e+04      0.002      0.999     -2.64e+04  2.65e+04\n",
      "ListingPrice          6.638e-05      0.000      0.259      0.795        -0.000     0.001\n",
      "SellerFeedbackRating    -0.0082      0.009     -0.907      0.364        -0.026     0.009\n",
      "ShipsFrom_BC             2.1562      0.144     14.986      0.000         1.874     2.438\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.22 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "print(logreg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(X_test[feature_cols])\n",
    "\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_logreg_pred = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949886104784\n",
      "Confusion matrix: \n",
      " [[1668    0]\n",
      " [  88    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      1668\n",
      "          1       0.00      0.00      0.00        88\n",
      "\n",
      "avg / total       0.90      0.95      0.93      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.175383\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df_newlog = df[['IsWinner', 'IsFeaturedMerchant', 'ShipsFrom_BC']]\n",
    "feature_cols = ['IsFeaturedMerchant', 'ShipsFrom_BC']\n",
    "logreg2 = sm.logit(formula = \"IsWinner ~ IsFeaturedMerchant + ShipsFrom_BC\", data=df_newlog).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 5851\n",
      "Model:                          Logit   Df Residuals:                     5848\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.1413\n",
      "Time:                        22:10:38   Log-Likelihood:                -1026.2\n",
      "converged:                      False   LL-Null:                       -1195.0\n",
      "                                        LLR p-value:                 4.775e-74\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept            -26.4101   1.51e+04     -0.002      0.999     -2.97e+04  2.97e+04\n",
      "IsFeaturedMerchant    23.4525   1.51e+04      0.002      0.999     -2.97e+04  2.97e+04\n",
      "ShipsFrom_BC           2.1575      0.143     15.043      0.000         1.876     2.439\n",
      "======================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.22 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "print(logreg2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg2.predict(X_test[feature_cols])\n",
    "\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_logreg_pred = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_logreg_pred[\"ActualClass\"], df_true_vs_logreg_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949886104784\n",
      "Confusion matrix: \n",
      " [[1668    0]\n",
      " [  88    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      1668\n",
      "          1       0.00      0.00      0.00        88\n",
      "\n",
      "avg / total       0.90      0.95      0.93      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['ListingPrice', 'IsFeaturedMerchant', 'SellerFeedbackRating', 'ShipsFrom_BC', 'ShipsFrom_PA']\n",
    "rfm = RandomForestRegressor(oob_score=True)\n",
    "rfm.fit(X_train[feature_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.076419608810107231"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Stat:  0.745037977524\n"
     ]
    }
   ],
   "source": [
    "#not sure whether to use y_train or y_test here? \n",
    "y_oob = rfm.oob_prediction_\n",
    "print(\"C-Stat: \", roc_auc_score(y_train, y_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rfm.predict(X_test[feature_cols])\n",
    "\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_rfm_pred = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_rfm_pred[\"ActualClass\"], df_true_vs_rfm_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_rfm_pred[\"ActualClass\"], df_true_vs_rfm_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_rfm_pred[\"ActualClass\"], df_true_vs_rfm_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.938496583144\n",
      "Confusion matrix: \n",
      " [[1613   55]\n",
      " [  53   35]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      1668\n",
      "          1       0.39      0.40      0.39        88\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pamel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['ListingPrice']\n",
    "rfm2 = RandomForestRegressor(oob_score=True)\n",
    "rfm2.fit(X_train[feature_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.095295176796352354"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Stat:  0.703970453439\n"
     ]
    }
   ],
   "source": [
    "y_oob = rfm2.oob_prediction_\n",
    "print(\"C-Stat: \", roc_auc_score(y_train, y_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rfm2.predict(X_test[feature_cols])\n",
    "\n",
    "predicted_class = list()\n",
    "for i in predictions:\n",
    "    if i >= 0.5:\n",
    "        predicted_class.append(1)\n",
    "    else:\n",
    "        predicted_class.append(0)\n",
    "        \n",
    "df_true_vs_rfm2_pred = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(df_true_vs_rfm2_pred[\"ActualClass\"], df_true_vs_rfm2_pred[\"PredictedClass\"])\n",
    "confusion_matrix = metrics.confusion_matrix(df_true_vs_rfm2_pred[\"ActualClass\"], df_true_vs_rfm2_pred[\"PredictedClass\"])\n",
    "class_report = metrics.classification_report(df_true_vs_rfm2_pred[\"ActualClass\"], df_true_vs_rfm2_pred[\"PredictedClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.938496583144\n",
      "Confusion matrix: \n",
      " [[1621   47]\n",
      " [  61   27]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97      1668\n",
      "          1       0.36      0.31      0.33        88\n",
      "\n",
      "avg / total       0.93      0.94      0.94      1756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "print(\"Classification report:\\n \", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Comparison Analysis: \n",
    "\n",
    "1. We can see no difference between the linear models trained and tested on the whole set and those trained and tested with the split set. \n",
    "2. The same goes for the logistic models. \n",
    "3. However, with the random forest we can see that the accuracy of the model is reduced by a few percent. This is valuable in that it shows us how testing the model on the same data you trained it on can produce a falsely high accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Summarize and try to improve your results so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 Which model performs best and is it more accurate than a simple (but useless) model that always predicts IsWinner=0? Justify your answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Random Forest Model definitely performed best. When trained on the training set and tested on the testing set it had an accuracy of 94% which is a pretty good model. This is surely preferable to a simple model that always predicts IsWinner = 0. Keep in mind that although the model has 94% accuracy it is not exactly the truth of the evaluation. Because there are a disproportionate number of the negative class we should also look at the percentage of true positives that the model was able to predict: 39%. We were able to predict a correct case of the positive class 39% of the time. This is still better than either of the linear or logistic regression models but would it be deployable in a real business scenario? Possibly not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 Discuss your understanding of the problem and predictive modeling results so far. Can you find  any tricks to improve the best model so far (e.g., using feature significance, feature rescaling, creating new features, combining models, or other knowledge)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the Problem and the Data Set:\n",
    "\n",
    "Having analysed the data set in depth I can see that there is no one feature that determines whether or not an offer will be determined a winner. It makes sense that a Random Forest model works better in this case because we don't have a clear numerical relationship between any one feature and the target feature. \n",
    "\n",
    "### Possible Improvements: \n",
    "\n",
    "1. We discussed in class the concept of ensembling. I think that using this in conjunction with Random Forest could produce a better outcome. Random Forest was the only model that predicted in the positive class (albeit exclusively so still useless). Perhaps introducing ensembling would give the model a better chance of predicting at a higher accuracy. \n",
    "2. We also discussed in class the concept of decision trees. These could be very useful for a problem like this where there is no one feature that determines a winner, but a number that have different levels of influence on the outcome. We could break down the problem so as to rule out edge cases (such as Listing Prices under 1500) and continue in this way until we have a good idea of which cases are likely to be in the positive clas. We could also weight different questions depending on the strength of the correlation between the descriptive feature in question and the target feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. http://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas\n",
    "2. http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "3. http://stackoverflow.com/questions/25125168/array-shape-giving-error-tuple-not-callable\n",
    "4. http://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\n",
    "5. http://stackoverflow.com/questions/20209600/panda-dataframe-remove-constant-column\n",
    "6. http://stackoverflow.com/questions/19482970/get-list-from-pandas-dataframe-column-headers\n",
    "7. http://stackoverflow.com/questions/36185883/python-pandas-dataframe-remove-columns-from-header\n",
    "8. https://chrisalbon.com/python/pandas_dropping_column_and_rows.html\n",
    "9. http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.DataFrame.to_csv.html\n",
    "10. http://stackoverflow.com/questions/20107570/removing-index-column-in-pandas\n",
    "11. http://stackoverflow.com/questions/9012487/matplotlib-pyplot-savefig-outputs-blank-image\n",
    "12. http://stackoverflow.com/questions/18172851/deleting-dataframe-row-in-pandas-based-on-column-value\n",
    "13. http://stackoverflow.com/questions/29017525/deleting-rows-based-on-multiple-conditions-python-pandas\n",
    "14. Lab Notebook - Notebook-Linear-Regression\n",
    "15. Lab Notebook - Notebook-Modeling-Logistic-Regression\n",
    "16. Lab Notebook - Notebook-Modeling-Random-Forest\n",
    "17. Lab 4 Notebook\n",
    "18. https://www.youtube.com/watch?v=0GrciaGYzV0&list=PLx1nh9sMznmKoUjw6uHR2enxCrenhn5zD&index=4\n",
    "19. https://github.com/justmarkham/DAT4/blob/master/notebooks/08_linear_regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
